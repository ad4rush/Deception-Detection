{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":297364,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":254426,"modelId":275826}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport re\nimport string\nimport glob\nimport warnings\nimport random\n\n# Scikit-learn imports\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.utils import resample # Added for downsampling\n\n# TensorFlow / Keras imports\nimport tensorflow as tf\nfrom tensorflow.keras.layers import (Input, Embedding, Dense, Dropout, Concatenate,\n                                     Layer, MultiHeadAttention, LayerNormalization,\n                                     GlobalAveragePooling1D, Add, Reshape,\n                                     Multiply)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# --- Constants and Configuration ---\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning) # Less verbose about build\n\nMAX_PLAYERS = 7; MAX_SEQUENCE_LENGTH = 60; EMBEDDING_DIM = 128; MAX_VOCAB_SIZE = 10000\nNUM_HEADS_TXT=4; NUM_HEADS_REASON=4; DROPOUT_RATE=0.1; GCN_UNITS=64\nDELTA_FEATURE_DIM=2\nLEARNING_RATE=1e-4; BATCH_SIZE=32; EPOCHS=30;\nPATIENCE=8\n\nBASE_DATA_DIR = '/kaggle/input/diplomacy/transformers/default/1/Dataset/'\nif not os.path.exists(BASE_DATA_DIR) and 'kaggle' not in BASE_DATA_DIR: BASE_DATA_DIR = './Dataset/'\nDATA_DIR = os.path.join(BASE_DATA_DIR, 'data')\nOUTPUT_DIR = '/kaggle/working/' if os.path.exists('/kaggle/working/') else './output/'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --- Helper Functions ---\n\ndef load_jsonl_dataset(file_path):\n    \"\"\"Loads data from a JSON Lines file, handling errors.\"\"\"\n    data = []\n    skipped_lines = 0\n    try: # Correct indentation for try\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f):\n                try:\n                    data.append(json.loads(line))\n                except json.JSONDecodeError:\n                    skipped_lines += 1\n                    # print(f\"Warn: Skipped invalid JSON line {i+1} in {file_path}\") # Uncomment for debug\n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        return None # Return None if file not found\n    if skipped_lines > 0:\n        print(f\"Warn: Skipped {skipped_lines} invalid JSON lines in {file_path}\")\n    return data\n\ndef clean_text(text):\n    \"\"\"Cleans text data.\"\"\"\n    if not isinstance(text, str): return \"\"\n    text = text.lower()\n    text = re.sub(r'http\\S+|@\\w+|#\\w+', '', text) # Remove urls, mentions, hashtags\n    text = text.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\"))) # Remove punctuation except apostrophe\n    text = re.sub(r'\\d+', '', text) # Remove digits\n    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n    return text\n\ndef preprocess_for_hybrid(data_raw):\n    \"\"\"Preprocesses raw data for hybrid model inputs.\"\"\"\n    processed_samples = []\n    if data_raw is None: return processed_samples\n    skipped_dialogues=0\n    for dialogue_idx, dialogue_sample in enumerate(data_raw):\n        # Extract necessary fields safely\n        game_id=dialogue_sample.get('game_id'); messages=dialogue_sample.get('messages',[]); speakers=dialogue_sample.get('speakers',[]); recipients=dialogue_sample.get('receivers',[])\n        years=dialogue_sample.get('years',[]); seasons=dialogue_sample.get('seasons',[]); sender_labels=dialogue_sample.get('sender_labels',[]); game_scores=dialogue_sample.get('game_score',[]); game_score_deltas=dialogue_sample.get('game_score_delta',[])\n        list_len=len(messages)\n        # Check for essential fields and consistent lengths\n        required_lists = [speakers, recipients, years, seasons, sender_labels, game_scores, game_score_deltas]\n        # Ensure all elements in required_lists are actually lists before checking length\n        if not (game_id and list_len > 0 and all(isinstance(lst, list) and len(lst) == list_len for lst in required_lists if lst is not None)):\n             skipped_dialogues+=1\n             continue\n\n\n        for i in range(list_len):\n            label=-1; score_num=np.nan; delta_num=np.nan\n            # Ensure sender_labels is a list and index i is valid\n            if isinstance(sender_labels, list) and i < len(sender_labels):\n                if sender_labels[i] is False: label=0\n                elif sender_labels[i] is True: label=1\n\n            # Safely access and convert score and delta\n            try:\n                if game_scores and i < len(game_scores): score_num=float(game_scores[i])\n            except (ValueError, TypeError): pass\n            try:\n                if game_score_deltas and i < len(game_score_deltas): delta_num=float(game_score_deltas[i])\n            except (ValueError, TypeError): pass\n\n            # Only keep samples with a valid label (0 or 1)\n            if label != -1:\n                processed_samples.append({\n                    'text': messages[i] if messages and i < len(messages) else \"\",\n                    'clean_text': clean_text(messages[i] if messages and i < len(messages) else \"\"),\n                    'label': label,\n                    'game_id': game_id,\n                    'year': str(years[i] if years and i < len(years) else 'unknown'),\n                    'season': str(seasons[i] if seasons and i < len(seasons) else 'unknown').lower(),\n                    'speaker': str(speakers[i] if speakers and i < len(speakers) else 'unknown').lower(),\n                    'recipient': str(recipients[i] if recipients and i < len(recipients) else 'unknown').lower(), # Needed for future delta calc\n                    'score_numeric': score_num,\n                    'delta_numeric': delta_num\n                    })\n    print(f\" Preprocessed {len(processed_samples)} labeled messages.\", end=\"\")\n    if skipped_dialogues > 0: print(f\" (Skipped {skipped_dialogues} dialogues)\", end=\"\")\n    print()\n    return processed_samples\n\ndef create_score_lookup(all_samples):\n    \"\"\"Creates a lookup dictionary for player scores.\"\"\"\n    score_lookup=defaultdict(lambda:np.nan); processed_keys=set(); valid_scores=0; skipped_no_score=0\n    print(f\"Creating score lookup from {len(all_samples)} samples...\")\n    for sample in all_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); player=sample.get('speaker'); score_num=sample.get('score_numeric')\n        if game_id is not None and year!='unknown' and season!='unknown' and player!='unknown': # Explicit check for game_id None\n            key=(game_id,year,season,player)\n            if key not in processed_keys:\n                if pd.notna(score_num): # Check if score_num is not NaN\n                    score_lookup[key]=score_num\n                    processed_keys.add(key)\n                    valid_scores+=1\n                else:\n                    skipped_no_score+=1\n    print(f\"Score lookup created: {len(score_lookup)} entries ({valid_scores} unique). Skipped N/A: {skipped_no_score}.\")\n    return score_lookup\n\ndef get_next_turn(current_year_str, current_season_str): # CORRECTED version\n    \"\"\"Calculates the next game turn (year, season).\"\"\"\n    try:\n        current_year = int(current_year_str)\n        current_season = str(current_season_str).lower() # Ensure season is lowercase string\n        if current_season == 'spring': return str(current_year), 'fall'\n        elif current_season == 'fall': return str(current_year), 'winter'\n        elif current_season == 'winter': return str(current_year + 1), 'spring'\n        else: return None, None\n    except (ValueError, TypeError):\n        return None, None\n\ndef extract_delta_features(sample_info, score_lookup): # CORRECTED version\n    \"\"\"Extracts current and future delta features for a message.\"\"\"\n    current_delta = 0.0; future_delta = 0.0\n    current_delta_val = sample_info.get('delta_numeric', 0.0)\n    if not pd.isna(current_delta_val):\n         try: current_delta = float(current_delta_val)\n         except (ValueError, TypeError): current_delta = 0.0\n    game_id=sample_info.get('game_id'); year=sample_info.get('year'); season=sample_info.get('season'); speaker=sample_info.get('speaker'); recipient=sample_info.get('recipient')\n    if game_id is not None and year!='unknown' and season!='unknown' and speaker!='unknown' and recipient!='unknown':\n        next_year, next_season = get_next_turn(year, season)\n        if next_year and next_season:\n            fut_spk_score = score_lookup.get((game_id, next_year, next_season, speaker), np.nan)\n            fut_rec_score = score_lookup.get((game_id, next_year, next_season, recipient), np.nan)\n            if pd.notna(fut_spk_score) and pd.notna(fut_rec_score):\n                try: # Correctly indented try-except\n                    future_delta = float(fut_spk_score) - float(fut_rec_score)\n                except (ValueError, TypeError):\n                    future_delta = 0.0 # Fallback\n    return np.array([current_delta, future_delta], dtype=np.float32)\n\ndef aggregate_data_by_turn(all_processed_samples):\n    \"\"\"Aggregates data by game turn (needed for graph building).\"\"\"\n    games_data = defaultdict(lambda: defaultdict(lambda: {'messages': [], 'players': set()}))\n    for sample in all_processed_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); speaker=sample.get('speaker'); recipient=sample.get('recipient')\n        if game_id is None or year=='unknown' or season=='unknown': continue # Skip if key components missing\n        turn_key=(year,season);\n        # Only add valid speakers/recipients to players set\n        player_set = set()\n        if speaker is not None and speaker != 'unknown': player_set.add(speaker)\n        if recipient is not None and recipient != 'unknown': player_set.add(recipient)\n        games_data[game_id][turn_key]['players'].update(player_set)\n        # Append message details for adjacency calc (make sure speaker/recipient aren't None if used later)\n        games_data[game_id][turn_key]['messages'].append({'speaker':speaker,'recipient':recipient})\n\n    print(f\"Aggregated samples into turns for {len(games_data)} games.\")\n    return games_data\n\ndef build_turn_graph_lookup(games_data_agg, score_lookup):\n    \"\"\"Builds a lookup for turn-specific graph data (X, A+I, M).\"\"\"\n    print(\"Building turn graph lookup (using A+I)...\"); graph_lookup={}; player_maps_game={}\n    default_graph = {'X': np.zeros((MAX_PLAYERS, 1), dtype=np.float32),\n                     'A': np.identity(MAX_PLAYERS, dtype=np.float32),\n                     'M': np.zeros(MAX_PLAYERS, dtype=bool)}\n    for game_id, turns in games_data_agg.items():\n        # Calculate player map for this game\n        all_p_in_game = set()\n        for turn_data in turns.values():\n            all_p_in_game.update(turn_data['players'])\n        # Ensure filtering out potential Nones before sorting\n        all_p_in_game = {p for p in all_p_in_game if p is not None}\n        if not all_p_in_game: continue # Skip game if no valid players identified\n\n        sorted_p = sorted(list(all_p_in_game)); p2i = {p:i for i,p in enumerate(sorted_p)}; i2p = {i:p for p,i in p2i.items()}; num_p_game=len(sorted_p)\n        player_maps_game[game_id]=(p2i, i2p)\n\n        if num_p_game == 0 or num_p_game > MAX_PLAYERS: continue # Skip if player count is invalid\n\n        for (yr,sn),t_data in turns.items():\n            tk=(game_id, yr, sn)\n            curr_p = sorted([p for p in t_data['players'] if p is not None]) # Ensure current players are valid\n            X = np.zeros((MAX_PLAYERS,1),dtype=np.float32); M = np.zeros(MAX_PLAYERS,dtype=bool)\n\n            for p in curr_p:\n                idx=p2i.get(p); # Look up index using game map\n                if idx is not None and idx < MAX_PLAYERS: # Ensure index is within bounds\n                    score=score_lookup.get((game_id,yr,sn,p), 0.0)\n                    X[idx,0]=0.0 if pd.isna(score) else float(score)\n                    M[idx]=True # Mark as present\n\n            # Adjacency based on messages in this turn\n            Ab=np.zeros((MAX_PLAYERS,MAX_PLAYERS),dtype=np.float32)\n            for msg in t_data['messages']:\n                # Get indices safely\n                i_s = p2i.get(msg.get('speaker'))\n                i_r = p2i.get(msg.get('recipient'))\n                # Add edge only if both speaker and recipient are mapped and valid indices\n                if i_s is not None and i_r is not None and i_s < MAX_PLAYERS and i_r < MAX_PLAYERS and i_s != i_r:\n                     Ab[i_s, i_r]=1.0; Ab[i_r, i_s]=1.0 # Undirected edge\n\n            Asl = Ab+np.identity(MAX_PLAYERS,dtype=np.float32) # Adjacency + Self-loops\n            graph_lookup[tk] = {'X':X,'A':Asl,'M':M}\n\n    # Fill any potential missing turn keys with default graph if needed by generator robustness\n    # This usually isn't necessary if data processing is clean.\n    print(f\"Graph lookup built:{len(graph_lookup)} turns.\");\n    return graph_lookup, player_maps_game\n\n# --- Module 1: Custom GCN Layer ---\nclass GCNLayer(Layer):\n    \"\"\" Basic Graph Convolutional Layer (A * X * W + b) \"\"\"\n    def __init__(self, units, activation=None, name=None, **kwargs):\n        super().__init__(name=name, **kwargs); self.units = units; self.activation = tf.keras.activations.get(activation)\n    def build(self, input_shape):\n        node_feature_shape, _ = input_shape # Expecting [X_shape, A_shape]\n        node_dim = node_feature_shape[-1]\n        self.w = self.add_weight(shape=(node_dim, self.units), initializer='glorot_uniform', name='w', trainable=True)\n        self.b = self.add_weight(shape=(self.units,), initializer='zeros', name='b', trainable=True)\n        super().build(input_shape) # Call parent build method\n    def call(self, inputs):\n        node_features, adj_matrix = inputs; support = tf.matmul(node_features, self.w); output = tf.matmul(adj_matrix, support); output = output + self.b;\n        if self.activation is not None: output = self.activation(output)\n        return output\n    def get_config(self):\n        config = super().get_config(); config.update({\"units\": self.units, \"activation\": tf.keras.activations.serialize(self.activation)}); return config\n    @classmethod\n    def from_config(cls, config):\n        activation_config = config.pop(\"activation\", None) # Extract activation config if present\n        activation = tf.keras.activations.deserialize(activation_config)\n        config['activation'] = activation # Add deserialized activation back\n        return cls(**config)\n\n\n# --- Module 2: Text + Delta Feature Encoder ---\nclass TextFeatureEncoder(Model):\n    \"\"\" Encodes text sequence and delta features into a combined embedding. \"\"\"\n    def __init__(self, max_vocab_size, embedding_dim, seq_len, num_heads, dropout_rate, delta_feature_dim, name=\"text_feature_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.embedding=Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, name='embedding'); self.mha=MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, name='attention'); self.add_norm1=Add(name='add_resid_1'); self.layernorm1=LayerNormalization(epsilon=1e-6, name='norm_1'); self.pooling=GlobalAveragePooling1D(name='text_pooling'); self.dropout_text1=Dropout(dropout_rate, name='text_dropout_1'); self.dense_features=Dense(16, activation='relu', name='dense_delta_features'); self.concatenate=Concatenate(name='concat_text_features'); self.dropout_combined=Dropout(dropout_rate*1.5, name='text_feature_dropout'); self.output_dim = embedding_dim; self.output_dense=Dense(self.output_dim, activation='relu', name='text_feature_output') # Ensure output dim defined\n    def call(self, inputs, training=False): text_input, feature_input = inputs; x_txt = self.embedding(text_input); attn_output = self.mha(query=x_txt, value=x_txt, key=x_txt); x_txt = self.add_norm1([x_txt, attn_output]); x_txt = self.layernorm1(x_txt); text_emb = self.pooling(x_txt); text_emb = self.dropout_text1(text_emb, training=training); feature_proc = self.dense_features(feature_input); combined = self.concatenate([text_emb, feature_proc]); combined_dropout = self.dropout_combined(combined, training=training); output_embedding = self.output_dense(combined_dropout); return output_embedding\n    def get_config(self): config=super().get_config(); config.update({'max_vocab_size':self.embedding.input_dim, 'embedding_dim':self.embedding.output_dim, 'seq_len':MAX_SEQUENCE_LENGTH, 'num_heads':self.mha.num_heads,'dropout_rate':self.dropout_text1.rate, 'delta_feature_dim':DELTA_FEATURE_DIM}); return config # Example parameters\n    @classmethod\n    def from_config(cls, config): return cls(**config)\n\n\n# --- Module 3: Graph Encoder ---\nclass GraphEncoder(Model):\n    \"\"\" Encodes graph structure and node features using custom GCN layers. \"\"\"\n    def __init__(self, max_players, node_feature_dim, gcn_units, dropout_rate, final_emb_dim, name=\"graph_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.max_players=max_players; self.final_emb_dim=final_emb_dim\n        self.gcn1=GCNLayer(gcn_units, activation='relu', name='CustomGCN1'); self.dropout_gcn1=Dropout(dropout_rate)\n        self.gcn2=GCNLayer(gcn_units, activation='relu', name='CustomGCN2'); self.dropout_gcn2=Dropout(dropout_rate)\n        self.gcn3=GCNLayer(gcn_units // 2, activation='relu', name='CustomGCN3')\n        self.graph_pooling=GlobalAveragePooling1D(name='GraphPooling'); self.dropout_pooled=Dropout(dropout_rate * 1.5)\n        self.output_dense=Dense(self.final_emb_dim, activation='relu', name='graph_output')\n    def call(self, inputs, training=False):\n        node_features, adj_matrix, node_mask = inputs; node_mask_float=tf.cast(node_mask,dtype=tf.float32); node_mask_expanded=tf.expand_dims(node_mask_float,axis=-1); masked_node_features=node_features*node_mask_expanded\n        x_graph = self.gcn1([masked_node_features, adj_matrix]); x_graph = self.dropout_gcn1(x_graph, training=training)\n        x_graph = self.gcn2([x_graph, adj_matrix]); x_graph = self.dropout_gcn2(x_graph, training=training)\n        x_graph = self.gcn3([x_graph, adj_matrix]);\n        x_graph._keras_mask = node_mask # Set mask before pooling\n        graph_emb_pooled = self.graph_pooling(x_graph); graph_emb_pooled = self.dropout_pooled(graph_emb_pooled, training=training); graph_embedding = self.output_dense(graph_emb_pooled)\n        return graph_embedding\n    def get_config(self): config = super().get_config(); config.update({'max_players':self.max_players,'node_feature_dim':1,'gcn_units':self.gcn1.units,'dropout_rate':self.dropout_gcn1.rate,'final_emb_dim':self.final_emb_dim}); return config\n    @classmethod\n    def from_config(cls, config): return cls(**config)\n\n# --- Module 4: Main Hybrid Model ---\nclass DiplomacyHybridModel(Model):\n    \"\"\" Combines text/feature and graph encoders using attention for classification. \"\"\"\n    def __init__(self, text_feature_encoder, graph_encoder, reason_dropout_rate, attention_heads, name=\"diplomacy_hybrid\", **kwargs):\n        super().__init__(name=name, **kwargs); self.text_feature_encoder = text_feature_encoder; self.graph_encoder = graph_encoder; self.concatenate = Concatenate(name='combine_embeddings')\n        # Calculate combined_dim dynamically based on sub-module output shapes IF THEY ARE BUILT\n        # This requires the sub-models to be built *before* the parent model __init__ runs fully,\n        # which is tricky. Easier to define expected dims or pass them in.\n        # Hardcoding based on current definition: text=EMBEDDING_DIM, graph=EMBEDDING_DIM//2\n        combined_dim = EMBEDDING_DIM + (EMBEDDING_DIM // 2)\n        self.reason_dense1 = Dense(combined_dim, activation='relu', name='reason_dense1'); self.dropout_reason1 = Dropout(reason_dropout_rate)\n        self.reshape_for_attn = Reshape((1, combined_dim)); attn_key_dim = max(16, combined_dim // attention_heads); self.attention_reason = MultiHeadAttention(num_heads=attention_heads, key_dim=attn_key_dim, name='reason_attention'); self.reshape_after_attn = Reshape((combined_dim,)); self.dropout_reason2 = Dropout(reason_dropout_rate)\n        self.output_classifier = Dense(1, activation='sigmoid', name='final_output')\n    def call(self, inputs, training=False):\n        text_input, feature_input, node_features, adj_matrix, node_mask = inputs\n        text_feat_emb = self.text_feature_encoder([text_input, feature_input], training=training)\n        graph_emb = self.graph_encoder([node_features, adj_matrix, node_mask], training=training)\n        combined = self.concatenate([text_feat_emb, graph_emb])\n        x = self.reason_dense1(combined); x = self.dropout_reason1(x, training=training)\n        x_reshaped = self.reshape_for_attn(x); attn_output = self.attention_reason(query=x_reshaped, value=x_reshaped, key=x_reshaped, training=training); x = self.reshape_after_attn(attn_output); x = self.dropout_reason2(x, training=training)\n        output = self.output_classifier(x)\n        return output\n    # get_config / from_config important for saving model correctly\n    def get_config(self):\n        # Serialize sub-modules by getting their configs\n        # This relies on submodules having proper get_config implemented\n        config = super().get_config()\n        config.update({\n            \"text_feature_encoder\": tf.keras.layers.serialize(self.text_feature_encoder),\n            \"graph_encoder\": tf.keras.layers.serialize(self.graph_encoder),\n            \"reason_dropout_rate\": self.dropout_reason1.rate,\n            \"attention_heads\": self.attention_reason.num_heads\n         })\n        return config\n    @classmethod\n    def from_config(cls, config):\n        # Deserialize sub-models before initializing parent\n        config[\"text_feature_encoder\"] = tf.keras.layers.deserialize(config[\"text_feature_encoder\"])\n        config[\"graph_encoder\"] = tf.keras.layers.deserialize(config[\"graph_encoder\"])\n        return cls(**config)\n\n\n# --- Main Script ---\nprint(\"--- Starting Hybrid GCN + Transformer (Modular, Downsampling, Predefined Splits, Corrected) ---\")\n\n# 1. Load Data from Separate Files\nprint(\"--- Loading Train/Val/Test Data ---\")\ntrain_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'train.jsonl'))\nval_raw   = load_jsonl_dataset(os.path.join(DATA_DIR, 'validation.jsonl'))\ntest_raw  = load_jsonl_dataset(os.path.join(DATA_DIR, 'test.jsonl'))\nif train_raw is None or val_raw is None or test_raw is None: raise ValueError(\"Failed to load data files.\")\nall_raw_data = train_raw + val_raw + test_raw # For lookups/tokenizer\n\n# 2. Preprocess ALL Data for Lookups\nprint(\"\\n--- Preprocessing ALL Data for Lookups ---\")\nall_processed = preprocess_for_hybrid(all_raw_data);\nif not all_processed: raise ValueError(\"Preprocessing failed.\")\nscore_lookup = create_score_lookup(all_processed)\ngames_data_agg = aggregate_data_by_turn(all_processed)\ngraph_lookup, _ = build_turn_graph_lookup(games_data_agg, score_lookup)\n\n# 3. Prepare SEPARATE Data Splits\nprint(\"\\n--- Preparing Train/Val/Test Data Splits ---\")\ntrain_processed = preprocess_for_hybrid(train_raw); val_processed = preprocess_for_hybrid(val_raw); test_processed = preprocess_for_hybrid(test_raw)\nif not train_processed or not val_processed or not test_processed: raise ValueError(\"Data splits empty after preprocessing.\")\n\n# 4. Fit Tokenizer (on ALL text) and Transform Splits\nprint(\"\\n--- Tokenizing Text Data ---\")\nall_texts = [s['clean_text'] for s in all_processed]\ntokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\ntokenizer.fit_on_texts(all_texts); vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index) + 1)\nprint(f\"Vocab size: {vocab_size}\")\ndef tokenize_and_pad(samples): texts=[s['clean_text'] for s in samples]; sequences=tokenizer.texts_to_sequences(texts); return pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post',truncating='post')\npadded_train=tokenize_and_pad(train_processed); padded_val=tokenize_and_pad(val_processed); padded_test=tokenize_and_pad(test_processed)\nprint(f\"Padded Shapes: Tr={padded_train.shape}, Vl={padded_val.shape}, Ts={padded_test.shape}\")\n\n# 5. Prepare Other Features/Labels for Splits\ndef extract_features_labels_keys(samples): labels=np.array([s['label'] for s in samples]); delta_feats=np.array([extract_delta_features(s, score_lookup) for s in samples]); turn_keys=[(s['game_id'],s['year'],s['season']) for s in samples]; return labels, delta_feats, turn_keys\nlabels_train, delta_feats_train, turn_keys_train = extract_features_labels_keys(train_processed)\nlabels_val, delta_feats_val, turn_keys_val = extract_features_labels_keys(val_processed)\nlabels_test, delta_feats_test, turn_keys_test = extract_features_labels_keys(test_processed)\n\n# 6. Apply Downsampling (ONLY on TRAINING data)\nprint(\"\\n--- Downsampling Training Data ---\")\ntrain_indices = np.arange(len(labels_train)); minority_indices = train_indices[labels_train == 0]; majority_indices = train_indices[labels_train == 1]\nprint(f\"Original Train counts: Lie(0)={len(minority_indices)}, Truth(1)={len(majority_indices)}\")\nif len(minority_indices)==0 or len(majority_indices)==0: raise ValueError(\"Cannot downsample, one class empty.\")\nmajority_downsampled_indices = resample(majority_indices, replace=False, n_samples=len(minority_indices), random_state=SEED)\ndownsampled_train_indices = np.concatenate([minority_indices, majority_downsampled_indices]); np.random.shuffle(downsampled_train_indices)\npadded_train_ds = padded_train[downsampled_train_indices]; delta_feats_train_ds = delta_feats_train[downsampled_train_indices]; labels_train_ds = labels_train[downsampled_train_indices]\nturn_keys_train_list = [turn_keys_train[i] for i in downsampled_train_indices]\nprint(f\"Downsampled Train counts: Lie(0)={sum(labels_train_ds==0)}, Truth(1)={sum(labels_train_ds==1)}\")\n\n# 7. Create tf.data.Datasets\nprint(\"\\n--- Creating tf.data Datasets ---\")\ndef get_graph_data_batch(keys): # Needs definition here\n    batch_X, batch_A, batch_M = [],[],[]; default_graph={'X':np.zeros((MAX_PLAYERS,1),dtype=np.float32),'A':np.identity(MAX_PLAYERS,dtype=np.float32),'M':np.zeros(MAX_PLAYERS,dtype=bool)};\n    for key in keys: graph_data=graph_lookup.get(key,default_graph); batch_X.append(graph_data['X']); batch_A.append(graph_data['A']); batch_M.append(graph_data['M']);\n    return np.array(batch_X),np.array(batch_A),np.array(batch_M)\ndef data_generator_split(text_padded_arr, delta_feats_arr, labels_arr, turn_keys_list): # Ensure defined before use\n    num_samples = len(labels_arr); indices = np.arange(num_samples)\n    for i in indices: text_pad=text_padded_arr[i]; delta_f=delta_feats_arr[i]; label=labels_arr[i]; turn_key=turn_keys_list[i]; X_g_batch, A_g_batch, M_g_batch = get_graph_data_batch([turn_key]); yield (text_pad, delta_f, X_g_batch[0], A_g_batch[0], M_g_batch[0]), label\noutput_signature=((tf.TensorSpec(shape=(MAX_SEQUENCE_LENGTH,),dtype=tf.int32), tf.TensorSpec(shape=(DELTA_FEATURE_DIM,),dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,1),dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,MAX_PLAYERS),dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,),dtype=tf.bool)), tf.TensorSpec(shape=(),dtype=tf.int32))\n# Create datasets\ntrain_dataset=tf.data.Dataset.from_generator(lambda:data_generator_split(padded_train_ds,delta_feats_train_ds,labels_train_ds,turn_keys_train_list),output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).repeat()\nval_dataset=tf.data.Dataset.from_generator(lambda:data_generator_split(padded_val,delta_feats_val,labels_val,turn_keys_val),output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\ntest_dataset=tf.data.Dataset.from_generator(lambda:data_generator_split(padded_test,delta_feats_test,labels_test,turn_keys_test),output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE); print(\"tf.data Datasets created.\")\n\n# 8. Build & Compile the MAIN Hybrid Model\nprint(\"\\n--- Building and Compiling Main Hybrid Model ---\")\ntext_encoder = TextFeatureEncoder(max_vocab_size=vocab_size, embedding_dim=EMBEDDING_DIM, seq_len=MAX_SEQUENCE_LENGTH,num_heads=NUM_HEADS_TXT, dropout_rate=DROPOUT_RATE, delta_feature_dim=DELTA_FEATURE_DIM)\ngraph_encoder = GraphEncoder(max_players=MAX_PLAYERS, node_feature_dim=1, gcn_units=GCN_UNITS,dropout_rate=DROPOUT_RATE, final_emb_dim=EMBEDDING_DIM // 2)\ndiplomacy_model = DiplomacyHybridModel(text_feature_encoder=text_encoder, graph_encoder=graph_encoder, reason_dropout_rate=0.3, attention_heads=NUM_HEADS_REASON)\ndiplomacy_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy']) # Compile with basic metrics\n# Build model explicitly by calling it once\ninput_specs = [spec for spec in output_signature[0]]\n# Use tf.keras.Input to define symbolic inputs based on specs\nsymbolic_inputs = [tf.keras.Input(batch_shape=(None,) + spec.shape[1:], dtype=spec.dtype) if spec.shape else tf.keras.Input(batch_shape=(None,), dtype=spec.dtype) for spec in input_specs ] # Handle scalar shape for label spec (though label is output) - need input specs only\ninput_shapes_only = [spec.shape for spec in output_signature[0]] # Shapes of the 5 inputs\ndiplomacy_model.build(input_shape=input_shapes_only) # Build expects list of shapes\ndiplomacy_model.summary(expand_nested=True)\n\n# 9. Train the Main Hybrid Model\nmodel_name_main_hybrid=\"DiplomacyModularHybrid_DS_Attn\"; main_hybrid_filename=model_name_main_hybrid.lower()+\".keras\"; main_hybrid_path=os.path.join(OUTPUT_DIR, f\"best_{main_hybrid_filename}\")\nmain_early_stopping=EarlyStopping(monitor='val_loss',patience=PATIENCE,verbose=1,restore_best_weights=True,mode='min'); main_checkpoint=ModelCheckpoint(main_hybrid_path,monitor='val_loss',save_best_only=True,mode='min',verbose=1)\nprint(f\"\\n--- Training Main Hybrid Model: {model_name_main_hybrid} ---\");\nsteps_per_epoch_train = len(downsampled_train_indices) // BATCH_SIZE\nif len(downsampled_train_indices) % BATCH_SIZE != 0: steps_per_epoch_train += 1\nhistory_main=diplomacy_model.fit(train_dataset,validation_data=val_dataset,epochs=EPOCHS,steps_per_epoch=steps_per_epoch_train,callbacks=[main_early_stopping, main_checkpoint],verbose=1)\n\n# 10. Evaluate the Main Hybrid Model...\nprint(f\"\\n--- Evaluating Main Hybrid Model on Test Set ---\")\nif os.path.exists(main_hybrid_path): diplomacy_model.load_weights(main_hybrid_path); print(\"Loaded best main hybrid weights.\")\nelse: print(\"Warn: Best main hybrid model file not found.\")\ntest_loss_mh, test_acc_mh = diplomacy_model.evaluate(test_dataset, verbose=1)\nprint(\"Generating predictions for detailed metrics...\")\ny_pred_probs_mh=diplomacy_model.predict(test_dataset); y_pred_bin_mh=(y_pred_probs_mh > 0.5).astype(int).flatten(); y_true_mh = labels_test\nf1_lie_mh=f1_score(y_true_mh, y_pred_bin_mh, pos_label=0, zero_division=0); f1_truth_mh=f1_score(y_true_mh, y_pred_bin_mh, pos_label=1, zero_division=0); f1_macro_mh=f1_score(y_true_mh, y_pred_bin_mh, average='macro', zero_division=0); f1_weighted_mh=f1_score(y_true_mh, y_pred_bin_mh, average='weighted', zero_division=0)\nprint(\"\\nMain Hybrid Model Test Results (Using Sklearn Metrics):\"); print(f\" Accuracy:{test_acc_mh:.4f}, Loss:{test_loss_mh:.4f}\"); print(f\" Macro F1:{f1_macro_mh:.4f}, Weighted F1:{f1_weighted_mh:.4f}\"); print(\"-\" * 20); print(classification_report(y_true_mh, y_pred_bin_mh, target_names=['Lie (0)', 'Truth (1)'], digits=4)); print(\"-\" * 20)\n\n# 11. Plot Confusion Matrix...\nconf_matrix_mh=confusion_matrix(y_true_mh, y_pred_bin_mh); plt.figure(figsize=(6,5)); sns.heatmap(conf_matrix_mh, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred Lie(0)','Pred Truth(1)'], yticklabels=['Actual Lie(0)','Actual Truth(1)']); plt.title(f'Hybrid Model (DS, Attn) CM\\nAcc:{test_acc_mh:.3f}|MacroF1:{f1_macro_mh:.3f}|Lie F1:{f1_lie_mh:.3f}',fontsize=9); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.tight_layout(); plot_cm_mh_path = os.path.join(OUTPUT_DIR, f\"cm_main_hybrid_ds_attn.png\");\ntry: plt.savefig(plot_cm_mh_path); print(f\"Saved CM plot: {plot_cm_mh_path}\")\nexcept Exception as e: print(f\"Error saving plot: {e}\")\nplt.show()\n\nprint(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T10:11:32.343895Z","iopub.execute_input":"2025-04-15T10:11:32.344683Z","iopub.status.idle":"2025-04-15T10:12:29.035111Z","shell.execute_reply.started":"2025-04-15T10:11:32.344651Z","shell.execute_reply":"2025-04-15T10:12:29.034456Z"}},"outputs":[{"name":"stdout","text":"--- Starting Hybrid GCN + Transformer (Modular, Downsampling, Predefined Splits, Corrected) ---\n--- Loading Train/Val/Test Data ---\n\n--- Preprocessing ALL Data for Lookups ---\n Preprocessed 17289 labeled messages. (Skipped 6 dialogues)\nCreating score lookup from 17289 samples...\nScore lookup created: 1389 entries (1389 unique). Skipped N/A: 0.\nAggregated samples into turns for 12 games.\nBuilding turn graph lookup (using A+I)...\nGraph lookup built:312 turns.\n\n--- Preparing Train/Val/Test Data Splits ---\n Preprocessed 13132 labeled messages. (Skipped 5 dialogues)\n Preprocessed 1416 labeled messages. (Skipped 1 dialogues)\n Preprocessed 2741 labeled messages.\n\n--- Tokenizing Text Data ---\nVocab size: 9946\nPadded Shapes: Tr=(13132, 60), Vl=(1416, 60), Ts=(2741, 60)\n\n--- Downsampling Training Data ---\nOriginal Train counts: Lie(0)=591, Truth(1)=12541\nDownsampled Train counts: Lie(0)=591, Truth(1)=591\n\n--- Creating tf.data Datasets ---\ntf.data Datasets created.\n\n--- Building and Compiling Main Hybrid Model ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"diplomacy_hybrid\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"diplomacy_hybrid\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mTextFeatureEncoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (\u001b[38;5;33mMultiHeadAttention\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (\u001b[38;5;33mAdd\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (\u001b[38;5;33mDropout\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (\u001b[38;5;33mDense\u001b[0m)    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (\u001b[38;5;33mDropout\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (\u001b[38;5;33mDense\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (\u001b[38;5;33mGraphEncoder\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_100 (\u001b[38;5;33mDropout\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_101 (\u001b[38;5;33mDropout\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_102 (\u001b[38;5;33mDropout\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (\u001b[38;5;33mDense\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (\u001b[38;5;33mConcatenate\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (\u001b[38;5;33mDense\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_103 (\u001b[38;5;33mDropout\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_26 (\u001b[38;5;33mReshape\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_27 (\u001b[38;5;33mReshape\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_104 (\u001b[38;5;33mDropout\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (\u001b[38;5;33mDense\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextFeatureEncoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphEncoder</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n--- Training Main Hybrid Model: DiplomacyModularHybrid_DS_Attn ---\nEpoch 1/30\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5121 - loss: 0.7925\nEpoch 1: val_loss improved from inf to 0.57153, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 212ms/step - accuracy: 0.5124 - loss: 0.7925 - val_accuracy: 0.9470 - val_loss: 0.5715\nEpoch 2/30\n\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5512 - loss: 0.7707\nEpoch 2: val_loss improved from 0.57153 to 0.52132, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5517 - loss: 0.7694 - val_accuracy: 0.9527 - val_loss: 0.5213\nEpoch 3/30\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5287 - loss: 0.7331\nEpoch 3: val_loss improved from 0.52132 to 0.49747, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5290 - loss: 0.7331 - val_accuracy: 0.9470 - val_loss: 0.4975\nEpoch 4/30\n\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5380 - loss: 0.7212\nEpoch 4: val_loss improved from 0.49747 to 0.47123, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5387 - loss: 0.7211 - val_accuracy: 0.9421 - val_loss: 0.4712\nEpoch 5/30\n\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5145 - loss: 0.7389\nEpoch 5: val_loss did not improve from 0.47123\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5160 - loss: 0.7375 - val_accuracy: 0.9160 - val_loss: 0.5219\nEpoch 6/30\n\u001b[1m29/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5659 - loss: 0.6867\nEpoch 6: val_loss improved from 0.47123 to 0.46336, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5711 - loss: 0.6844 - val_accuracy: 0.9209 - val_loss: 0.4634\nEpoch 7/30\n\u001b[1m28/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5850 - loss: 0.6874\nEpoch 7: val_loss improved from 0.46336 to 0.46041, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5801 - loss: 0.6869 - val_accuracy: 0.9202 - val_loss: 0.4604\nEpoch 8/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6692\nEpoch 8: val_loss improved from 0.46041 to 0.45140, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5988 - loss: 0.6681 - val_accuracy: 0.9110 - val_loss: 0.4514\nEpoch 9/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6989\nEpoch 9: val_loss did not improve from 0.45140\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6106 - loss: 0.6927 - val_accuracy: 0.8969 - val_loss: 0.4710\nEpoch 10/30\n\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5874 - loss: 0.6818\nEpoch 10: val_loss did not improve from 0.45140\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5892 - loss: 0.6800 - val_accuracy: 0.9025 - val_loss: 0.4861\nEpoch 11/30\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6120 - loss: 0.6685\nEpoch 11: val_loss did not improve from 0.45140\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6122 - loss: 0.6681 - val_accuracy: 0.8976 - val_loss: 0.4763\nEpoch 12/30\n\u001b[1m28/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6080 - loss: 0.6600\nEpoch 12: val_loss did not improve from 0.45140\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6097 - loss: 0.6561 - val_accuracy: 0.8997 - val_loss: 0.4861\nEpoch 13/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6307 - loss: 0.6325\nEpoch 13: val_loss did not improve from 0.45140\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6361 - loss: 0.6292 - val_accuracy: 0.8877 - val_loss: 0.4776\nEpoch 14/30\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6781 - loss: 0.5953\nEpoch 14: val_loss improved from 0.45140 to 0.44764, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6784 - loss: 0.5949 - val_accuracy: 0.8764 - val_loss: 0.4476\nEpoch 15/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6735 - loss: 0.5831\nEpoch 15: val_loss improved from 0.44764 to 0.38206, saving model to /kaggle/working/best_diplomacymodularhybrid_ds_attn.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6779 - loss: 0.5807 - val_accuracy: 0.9068 - val_loss: 0.3821\nEpoch 16/30\n\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7308 - loss: 0.5328\nEpoch 16: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7354 - loss: 0.5281 - val_accuracy: 0.7302 - val_loss: 0.6429\nEpoch 17/30\n\u001b[1m29/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7947 - loss: 0.4593\nEpoch 17: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7977 - loss: 0.4550 - val_accuracy: 0.8150 - val_loss: 0.5114\nEpoch 18/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4389\nEpoch 18: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8150 - loss: 0.4274 - val_accuracy: 0.7486 - val_loss: 0.6566\nEpoch 19/30\n\u001b[1m29/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 0.3496\nEpoch 19: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8568 - loss: 0.3400 - val_accuracy: 0.7444 - val_loss: 0.7317\nEpoch 20/30\n\u001b[1m31/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.2897\nEpoch 20: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8818 - loss: 0.2856 - val_accuracy: 0.7168 - val_loss: 0.8828\nEpoch 21/30\n\u001b[1m31/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.2799\nEpoch 21: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8840 - loss: 0.2768 - val_accuracy: 0.8644 - val_loss: 0.4713\nEpoch 22/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4185\nEpoch 22: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8256 - loss: 0.4069 - val_accuracy: 0.7218 - val_loss: 0.8143\nEpoch 23/30\n\u001b[1m30/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.2828\nEpoch 23: val_loss did not improve from 0.38206\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8838 - loss: 0.2776 - val_accuracy: 0.6405 - val_loss: 1.0831\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 15.\n\n--- Evaluating Main Hybrid Model on Test Set ---\nLoaded best main hybrid weights.\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8903 - loss: 0.4088\nGenerating predictions for detailed metrics...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step\n\nMain Hybrid Model Test Results (Using Sklearn Metrics):\n Accuracy:0.8592, Loss:0.4427\n Macro F1:0.5842, Weighted F1:0.8631\n--------------------\n              precision    recall  f1-score   support\n\n     Lie (0)     0.2316    0.2625    0.2461       240\n   Truth (1)     0.9283    0.9164    0.9223      2501\n\n    accuracy                         0.8592      2741\n   macro avg     0.5800    0.5895    0.5842      2741\nweighted avg     0.8673    0.8592    0.8631      2741\n\n--------------------\nSaved CM plot: /kaggle/working/cm_main_hybrid_ds_attn.png\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n--- Script Finished ---\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport re\nimport string\nimport glob\nimport warnings\nimport random\nimport time # For timing FastText loading\n\n# Scikit-learn imports\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.utils import resample # Added for downsampling\n\n# TensorFlow / Keras imports\nimport tensorflow as tf\nfrom tensorflow import keras\n# Import layers alias *before* custom layer definition\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n# Explicitly import specific layers used\nfrom tensorflow.keras.layers import (Input, Embedding, Dense, Dropout, Concatenate,\n                                     Layer, LSTM, Bidirectional, # Removed Attention\n                                     GlobalAveragePooling1D, GlobalMaxPooling1D,\n                                     Multiply, Reshape, Lambda, Add, Activation) # Added Add, Activation\nfrom tensorflow.keras.optimizers import AdamW # Explicitly import AdamW\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# --- Constants and Configuration (Refined based on discussion) ---\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning) # Less verbose about build\n\n# Data/Model Paths\nBASE_DATA_DIR = './Dataset/' # Default if Kaggle path doesn't exist\nKAGGLE_DATA_DIR = '/kaggle/input/diplomacy/transformers/default/1/Dataset/'\nif os.path.exists(KAGGLE_DATA_DIR):\n    BASE_DATA_DIR = KAGGLE_DATA_DIR\nDATA_DIR = os.path.join(BASE_DATA_DIR, 'data')\nOUTPUT_DIR = '/kaggle/working/' if os.path.exists('/kaggle/working/') else './output/'\n# Make sure this path is correct for your environment (Kaggle example)\nFASTTEXT_PATH = '/kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n# FASTTEXT_PATH = './crawl-300d-2M.vec' # Example local path (download needed)\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Model Hyperparameters\nMAX_SEQUENCE_LENGTH = 80    # Based on message length distribution\nMAX_VOCAB_SIZE = 10000      # Max words to consider based on frequency\nEMBEDDING_DIM = 300         # Match FastText vectors (or choose 100 if using 100d vectors)\nLSTM_UNITS = 64             # Reduced units for smaller dataset\nGCN_UNITS = 64\nDENSE_UNITS = 128           # Projection dim for text/delta\nFINAL_MLP_UNITS = 96\nDROPOUT_RATE = 0.35         # Increased dropout for regularization\nRECURRENT_DROPOUT_RATE = 0.25 # LSTM recurrent dropout\n\n# Training Hyperparameters\nLEARNING_RATE = 5e-4\nWEIGHT_DECAY = 1e-4\nBATCH_SIZE = 32\nEPOCHS = 60                 # Increased epochs with early stopping\nPATIENCE = 10               # Early stopping patience\n\n# Other Constants\nMAX_PLAYERS = 7\nNODE_FEATURE_DIM = 1        # Player score\nDELTA_FEATURE_DIM = 2\n\n# --- Helper Functions (Keep all your helper functions: load_jsonl_dataset, etc.) ---\n# [Functions load_jsonl_dataset, clean_text, preprocess_for_hybrid, create_score_lookup,\n#  get_next_turn, extract_delta_features, aggregate_data_by_turn, build_turn_graph_lookup\n#  remain the same as the previous correct version]\ndef load_jsonl_dataset(file_path):\n    \"\"\"Loads data from a JSON Lines file, handling errors.\"\"\"\n    data = []\n    skipped_lines = 0\n    try: # Correct indentation for try\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f):\n                try:\n                    data.append(json.loads(line))\n                except json.JSONDecodeError:\n                    skipped_lines += 1\n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        return None\n    if skipped_lines > 0:\n        print(f\"Warn: Skipped {skipped_lines} invalid JSON lines in {file_path}\")\n    return data\n\ndef clean_text(text):\n    \"\"\"Cleans text data.\"\"\"\n    if not isinstance(text, str): return \"\"\n    text = text.lower()\n    text = re.sub(r'http\\S+|@\\w+|#\\w+', '', text)\n    text = text.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\")))\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef preprocess_for_hybrid(data_raw):\n    \"\"\"Preprocesses raw data for hybrid model inputs.\"\"\"\n    processed_samples = []\n    if data_raw is None: return processed_samples\n    skipped_dialogues=0\n    for dialogue_idx, dialogue_sample in enumerate(data_raw):\n        game_id=dialogue_sample.get('game_id'); messages=dialogue_sample.get('messages',[]); speakers=dialogue_sample.get('speakers',[]); recipients=dialogue_sample.get('receivers',[])\n        years=dialogue_sample.get('years',[]); seasons=dialogue_sample.get('seasons',[]); sender_labels=dialogue_sample.get('sender_labels',[]); game_scores=dialogue_sample.get('game_score',[]); game_score_deltas=dialogue_sample.get('game_score_delta',[])\n        list_len=len(messages)\n        required_lists = [speakers, recipients, years, seasons, sender_labels, game_scores, game_score_deltas]\n        if not (game_id and list_len > 0 and sender_labels is not None and\n                all(isinstance(lst, list) and len(lst) == list_len for lst in required_lists if lst is not None)):\n             skipped_dialogues+=1\n             continue\n\n        for i in range(list_len):\n            label=-1; score_num=np.nan; delta_num=np.nan\n            if isinstance(sender_labels, list) and i < len(sender_labels):\n                if sender_labels[i] is False: label=0\n                elif sender_labels[i] is True: label=1\n            else: continue\n\n            try:\n                if game_scores and i < len(game_scores) and game_scores[i] is not None: score_num=float(game_scores[i])\n            except (ValueError, TypeError): pass\n            try:\n                if game_score_deltas and i < len(game_score_deltas) and game_score_deltas[i] is not None: delta_num=float(game_score_deltas[i])\n            except (ValueError, TypeError): pass\n\n            if label != -1:\n                processed_delta = delta_num if pd.notna(delta_num) else 0.0\n                processed_samples.append({\n                    'text': messages[i] if messages and i < len(messages) else \"\",\n                    'clean_text': clean_text(messages[i] if messages and i < len(messages) else \"\"),\n                    'label': label, 'game_id': game_id, 'year': str(years[i] if years and i < len(years) else 'unknown'),\n                    'season': str(seasons[i] if seasons and i < len(seasons) else 'unknown').lower(),\n                    'speaker': str(speakers[i] if speakers and i < len(speakers) else 'unknown').lower(),\n                    'recipient': str(recipients[i] if recipients and i < len(recipients) else 'unknown').lower(),\n                    'score_numeric': score_num, 'delta_numeric': processed_delta\n                    })\n    print(f\" Preprocessed {len(processed_samples)} labeled messages.\", end=\"\")\n    if skipped_dialogues > 0: print(f\" (Skipped {skipped_dialogues} dialogues due to data issues)\", end=\"\")\n    print()\n    return processed_samples\n\ndef create_score_lookup(all_samples):\n    \"\"\"Creates a lookup dictionary for player scores (using score_numeric).\"\"\"\n    score_lookup=defaultdict(lambda:np.nan); processed_keys=set(); valid_scores=0; skipped_no_score=0\n    print(f\"Creating score lookup from {len(all_samples)} samples...\")\n    for sample in all_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); player=sample.get('speaker'); score_num=sample.get('score_numeric')\n        if game_id is not None and year!='unknown' and season!='unknown' and player!='unknown':\n            key=(game_id,year,season,player)\n            if key not in processed_keys:\n                if pd.notna(score_num): score_lookup[key]=score_num; valid_scores+=1\n                else: skipped_no_score+=1\n                processed_keys.add(key)\n    print(f\"Score lookup created: {len(score_lookup)} unique player-turn entries found.\")\n    print(f\"  - Entries with valid scores: {valid_scores}\")\n    print(f\"  - Entries where score was NaN: {skipped_no_score}\")\n    return score_lookup\n\ndef get_next_turn(current_year_str, current_season_str):\n    \"\"\"Calculates the next game turn (year, season).\"\"\"\n    try:\n        current_year = int(current_year_str)\n        current_season = str(current_season_str).lower()\n        if current_season == 'spring': return str(current_year), 'fall'\n        elif current_season == 'fall': return str(current_year), 'winter'\n        elif current_season == 'winter': return str(current_year + 1), 'spring'\n        else: return None, None\n    except (ValueError, TypeError): return None, None\n\ndef extract_delta_features(sample_info, score_lookup):\n    \"\"\"Extracts current and future delta features for a message.\"\"\"\n    current_delta = sample_info.get('delta_numeric', 0.0)\n    future_delta = 0.0\n    game_id=sample_info.get('game_id'); year=sample_info.get('year'); season=sample_info.get('season'); speaker=sample_info.get('speaker'); recipient=sample_info.get('recipient')\n    if game_id is not None and year!='unknown' and season!='unknown' and speaker!='unknown' and recipient!='unknown':\n        next_year, next_season = get_next_turn(year, season)\n        if next_year and next_season:\n            fut_spk_score = score_lookup.get((game_id, next_year, next_season, speaker), np.nan)\n            fut_rec_score = score_lookup.get((game_id, next_year, next_season, recipient), np.nan)\n            if pd.notna(fut_spk_score) and pd.notna(fut_rec_score):\n                try: future_delta = float(fut_spk_score) - float(fut_rec_score)\n                except (ValueError, TypeError): future_delta = 0.0\n    return np.array([current_delta, future_delta], dtype=np.float32)\n\ndef aggregate_data_by_turn(all_processed_samples):\n    \"\"\"Aggregates data by game turn (needed for graph building).\"\"\"\n    games_data = defaultdict(lambda: defaultdict(lambda: {'messages': [], 'players': set()}))\n    for sample in all_processed_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); speaker=sample.get('speaker'); recipient=sample.get('recipient')\n        if game_id is None or year=='unknown' or season=='unknown': continue\n        turn_key=(year,season);\n        player_set = set()\n        if speaker is not None and speaker != 'unknown': player_set.add(speaker)\n        if recipient is not None and recipient != 'unknown': player_set.add(recipient)\n        if player_set:\n             games_data[game_id][turn_key]['players'].update(player_set)\n             games_data[game_id][turn_key]['messages'].append({'speaker':speaker,'recipient':recipient})\n    print(f\"Aggregated samples into turns for {len(games_data)} games.\")\n    return games_data\n\ndef build_turn_graph_lookup(games_data_agg, score_lookup):\n    \"\"\"Builds a lookup for turn-specific graph data (X, A+I, M).\"\"\"\n    print(\"Building turn graph lookup (using A+I)...\")\n    graph_lookup={}\n    player_maps_game={}\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32)\n    default_A = np.identity(MAX_PLAYERS, dtype=np.float32)\n    default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}\n    skipped_games_players = 0\n    processed_turns = 0\n    for game_id, turns in games_data_agg.items():\n        all_p_in_game = set()\n        for turn_data in turns.values():\n            valid_players_in_turn = {p for p in turn_data['players'] if p is not None and p != 'unknown'}\n            all_p_in_game.update(valid_players_in_turn)\n        if not all_p_in_game: skipped_games_players += 1; continue\n        sorted_p = sorted(list(all_p_in_game))\n        num_p_game = len(sorted_p)\n        if num_p_game > MAX_PLAYERS:\n             sorted_p = sorted_p[:MAX_PLAYERS]\n             num_p_game = MAX_PLAYERS\n        p2i = {p: i for i, p in enumerate(sorted_p)}\n        player_maps_game[game_id] = p2i\n        for (yr, sn), t_data in turns.items():\n            tk = (game_id, yr, sn)\n            X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32)\n            M = np.zeros(MAX_PLAYERS, dtype=bool)\n            Ab = np.zeros((MAX_PLAYERS, MAX_PLAYERS), dtype=np.float32)\n            current_turn_players = {p for p in t_data['players'] if p is not None and p != 'unknown'}\n            for p in current_turn_players:\n                idx = p2i.get(p)\n                if idx is not None:\n                    score = score_lookup.get((game_id, yr, sn, p), np.nan)\n                    X[idx, 0] = 0.0 if pd.isna(score) else float(score)\n                    M[idx] = True\n            for msg in t_data['messages']:\n                i_s = p2i.get(msg.get('speaker')); i_r = p2i.get(msg.get('recipient'))\n                if i_s is not None and i_r is not None and i_s != i_r: Ab[i_s, i_r] = 1.0; Ab[i_r, i_s] = 1.0\n            Asl = Ab + np.identity(MAX_PLAYERS, dtype=np.float32)\n            graph_lookup[tk] = {'X': X, 'A': Asl, 'M': M}; processed_turns += 1\n    print(f\"Graph lookup built: {processed_turns} turns processed.\")\n    if skipped_games_players > 0: print(f\"Skipped {skipped_games_players} games due to no valid players or exceeding MAX_PLAYERS.\")\n    return graph_lookup, player_maps_game\n\n# --- GCN Layer Definition ---\nclass GCNLayer(layers.Layer):\n    \"\"\" Basic Graph Convolutional Layer (A * X * W + b) \"\"\"\n    def __init__(self, units, activation=None, name=None, **kwargs):\n        super().__init__(name=name, **kwargs); self.units = units; self.activation = tf.keras.activations.get(activation)\n    def build(self, input_shape):\n        node_feature_shape = tf.TensorShape(input_shape[0]); node_dim = int(node_feature_shape[-1])\n        self.w = self.add_weight(shape=(node_dim, self.units), initializer='glorot_uniform', name='w', trainable=True)\n        self.b = self.add_weight(shape=(self.units,), initializer='zeros', name='b', trainable=True)\n        super().build(input_shape)\n    def call(self, inputs):\n        node_features, adj_matrix = inputs; support = tf.matmul(node_features, self.w); output = tf.matmul(adj_matrix, support); output = output + self.b\n        if self.activation is not None: output = self.activation(output)\n        return output\n    def get_config(self): config = super().get_config(); config.update({\"units\": self.units, \"activation\": tf.keras.activations.serialize(self.activation)}); return config\n    @classmethod\n    def from_config(cls, config): activation_config = config.pop(\"activation\", None); activation = tf.keras.activations.deserialize(activation_config) if activation_config else None; config['activation'] = activation; return cls(**config)\n\n\n# --- Model Building Function (LGF-RN) ---\ndef build_lgf_rn_model(vocab_size, max_seq_len, embedding_dim, lstm_units,\n                       delta_dim, max_players, node_feat_dim, gcn_units,\n                       dense_units, final_mlp_units, dropout_rate, rec_dropout_rate,\n                       embedding_matrix=None):\n    \"\"\"Builds the Lightweight Graph-Fused Recurrent Network model.\"\"\"\n\n    # === Inputs ===\n    text_input = layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='text_input')\n    delta_input = layers.Input(shape=(delta_dim,), dtype=tf.float32, name='delta_input')\n    graph_nodes_input = layers.Input(shape=(max_players, node_feat_dim), dtype=tf.float32, name='graph_nodes_input')\n    graph_adj_input = layers.Input(shape=(max_players, max_players), dtype=tf.float32, name='graph_adj_input')\n    graph_mask_input = layers.Input(shape=(max_players,), dtype=tf.bool, name='graph_mask_input') # Mask for pooling\n\n    # === Text & Delta Encoder ===\n    if embedding_matrix is not None:\n        print(\"Initializing Embedding layer with pre-trained weights.\")\n        embedding_layer = layers.Embedding(\n            input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_len,\n            weights=[embedding_matrix], trainable=True, mask_zero=True, name='token_embedding'\n        )\n    else:\n        print(\"Initializing Embedding layer from scratch.\")\n        embedding_layer = layers.Embedding(\n            input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_len,\n            trainable=True, mask_zero=True, name='token_embedding'\n        )\n    embedded_text = embedding_layer(text_input)\n    text_mask = embedding_layer.compute_mask(text_input)\n\n    bilstm_out = layers.Bidirectional(layers.LSTM(\n        units=lstm_units, return_sequences=True,\n        dropout=dropout_rate, recurrent_dropout=rec_dropout_rate\n    ), name='bilstm')(embedded_text)\n\n    # --- Alternative Attention Application ---\n    query_context = layers.GlobalMaxPooling1D()(bilstm_out)\n    query_context_expanded = layers.Reshape((1, lstm_units * 2))(query_context)\n\n    attention_dense_value = layers.Dense(lstm_units * 2, use_bias=False, name='attn_dense_v')(bilstm_out)\n    attention_dense_query = layers.Dense(lstm_units * 2, use_bias=False, name='attn_dense_q')(query_context_expanded)\n    added_tensors = layers.Add(name='add_attn_query_value')([attention_dense_value, attention_dense_query])\n    scores_additive = layers.Activation('tanh', name='tanh_attn_scores')(added_tensors) # Corrected line\n\n    attention_scorer = layers.Dense(1, use_bias=False, name='attn_scorer')\n    scores = attention_scorer(scores_additive) # Shape: (b, 80, 1)\n    # Use Reshape layer instead of tf.squeeze\n    scores = layers.Reshape((max_seq_len,), name='squeeze_attn_scores')(scores) # Corrected line, target shape (b, 80)\n\n    # Apply Masking to Scores using Lambda layers\n    if text_mask is not None:\n        mask_float = layers.Lambda(lambda m: tf.cast(m, tf.float32), name='cast_text_mask_float')(text_mask)\n        adder = layers.Lambda(lambda m: (1.0 - m) * -1e9, name='create_mask_penalty')(mask_float)\n        scores = layers.Add(name='add_mask_penalty_to_scores')([scores, adder])\n\n    # Calculate Attention Weights (Softmax) using Lambda layer\n    attention_weights = layers.Lambda(lambda x: tf.nn.softmax(x, axis=1), name='attention_softmax')(scores) # Shape: (b, 80)\n\n    # Compute Weighted Sum (Context Vector) using Lambda layers\n    attention_weights_expanded = layers.Reshape((max_seq_len, 1), name='expand_attn_weights')(attention_weights) # Use Reshape\n\n    context_vector_lambda = layers.Lambda(\n        lambda x: tf.reduce_sum(x[0] * x[1], axis=1), name='weighted_sum_context'\n    )\n    text_emb = context_vector_lambda([bilstm_out, attention_weights_expanded]) # Shape: (b, 128)\n    # --- End Alternative Attention Application ---\n\n\n    # Delta Feature Processing MLP\n    delta_mlp = layers.Dense(16, activation='relu', name='delta_dense1')(delta_input)\n    delta_emb = layers.Dense(32, activation='relu', name='delta_dense2')(delta_mlp)\n\n    # Concatenate and Project Text/Delta\n    concatenated_text_delta = layers.Concatenate(name='concat_text_delta')([text_emb, delta_emb])\n    text_delta_fused_emb = layers.Dense(dense_units, activation='relu', name='proj_text_delta')(concatenated_text_delta)\n    text_delta_fused_emb = layers.Dropout(dropout_rate)(text_delta_fused_emb)\n\n    # === Graph Encoder ===\n    node_mask_float = layers.Lambda(lambda x: tf.cast(x, dtype=tf.float32), name='cast_mask_to_float')(graph_mask_input)\n    node_mask_expanded = layers.Reshape((max_players, 1), name='expand_mask_dim')(node_mask_float)\n    masked_node_features = layers.Multiply(name='mask_nodes')([graph_nodes_input, node_mask_expanded])\n\n    gcn1_out = GCNLayer(gcn_units, activation='relu', name='gcn1')([masked_node_features, graph_adj_input])\n    gcn1_out = layers.Dropout(dropout_rate)(gcn1_out)\n    gcn2_out = GCNLayer(gcn_units, activation='relu', name='gcn2')([gcn1_out, graph_adj_input])\n    gcn2_out = layers.Dropout(dropout_rate)(gcn2_out)\n\n    graph_pooled = layers.GlobalAveragePooling1D(name='graph_pooling')(gcn2_out, mask=graph_mask_input)\n\n    graph_emb = layers.Dense(dense_units // 2, activation='relu', name='proj_graph')(graph_pooled)\n    graph_emb = layers.Dropout(dropout_rate)(graph_emb)\n\n    # === Fusion Module ===\n    concatenated_final = layers.Concatenate(name='concat_final')([text_delta_fused_emb, graph_emb])\n\n    final_mlp = layers.Dense(final_mlp_units, activation='relu', name='final_mlp_dense')(concatenated_final)\n    final_mlp = layers.Dropout(dropout_rate * 1.5)(final_mlp)\n\n    # === Output Head ===\n    output_prob = layers.Dense(1, activation='sigmoid', name='output_prob')(final_mlp)\n\n    # === Create Model ===\n    model = Model(\n        inputs=[text_input, delta_input, graph_nodes_input, graph_adj_input, graph_mask_input],\n        outputs=output_prob,\n        name=\"LGF_RN_Model\"\n    )\n    return model\n\n# --- FastText Loading Function ---\n# [Keep the FastText loading function as before]\ndef load_fasttext_embedding_matrix(filepath, word_index, embedding_dim, max_vocab_size): # Added max_vocab_size\n    \"\"\"Loads FastText vectors and creates an embedding matrix.\"\"\"\n    print(f\"Loading FastText vectors from: {filepath}\")\n    if not os.path.exists(filepath):\n        print(f\"Error: FastText file not found at {filepath}\")\n        return None\n    start_time = time.time()\n    embeddings_index = {}\n    skipped_lines = 0\n    skipped_dims = 0\n    try:\n        with open(filepath, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n            for i, line in enumerate(f):\n                if i == 0 and len(line.split()) == 2:\n                    try:\n                        int(line.split()[0])\n                        # print(f\"Skipping potential FastText header: {line.strip()}\")\n                        continue\n                    except ValueError: pass\n\n                values = line.split()\n                word = values[0]\n                try:\n                    coefs = np.asarray(values[1:], dtype='float32')\n                    if len(coefs) == embedding_dim: embeddings_index[word] = coefs\n                    else: skipped_dims += 1\n                except ValueError: skipped_lines += 1; continue\n\n    except Exception as e: print(f\"An error occurred during FastText file reading: {e}\"); return None\n\n    load_time = time.time() - start_time\n    print(f\"Found {len(embeddings_index)} word vectors in {load_time:.2f} seconds.\")\n    if skipped_lines > 0: print(f\"  Skipped {skipped_lines} lines due to parsing errors.\")\n    if skipped_dims > 0: print(f\"  Skipped {skipped_dims} words due to incorrect dimensions (expected {embedding_dim}).\")\n\n    num_tokens = min(max_vocab_size, len(word_index) + 1)\n    hits = 0; misses = 0\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n\n    for word, i in word_index.items():\n        if i >= num_tokens: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector; hits += 1\n        else: misses += 1\n\n    print(f\"Prepared embedding matrix: Shape {embedding_matrix.shape}\")\n    print(f\"  Converted {hits} words from word_index ({misses} misses within vocab limit).\")\n    return embedding_matrix\n\n# --- Data Generator Function ---\n# [Keep the Data Generator function as before]\ndef data_generator_split(text_padded_arr, delta_feats_arr, labels_arr, turn_keys_list, graph_lookup):\n    \"\"\"Generates batches of data for Keras model training/evaluation.\"\"\"\n    num_samples = len(labels_arr)\n    indices = np.arange(num_samples)\n\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32)\n    default_A = np.identity(MAX_PLAYERS, dtype=np.float32)\n    default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}\n\n    for i in indices:\n        text_pad = text_padded_arr[i]; delta_f = delta_feats_arr[i]; label = labels_arr[i]; turn_key = turn_keys_list[i]\n        graph_data = graph_lookup.get(turn_key, default_graph)\n        X_g = graph_data.get('X', default_graph['X']); A_g = graph_data.get('A', default_graph['A']); M_g = graph_data.get('M', default_graph['M'])\n        if X_g.shape != (MAX_PLAYERS, NODE_FEATURE_DIM) or A_g.shape != (MAX_PLAYERS, MAX_PLAYERS) or M_g.shape != (MAX_PLAYERS,):\n            X_g, A_g, M_g = default_graph['X'], default_graph['A'], default_graph['M']\n        yield (text_pad, delta_f, X_g, A_g, M_g), label\n\n# --- Main Training Script ---\nif __name__ == \"__main__\":\n    # [Keep Steps 1-7: Load Data, Preprocess, Tokenize, Prep Splits, Downsample, Load Embeddings, Create Datasets]\n    # 1. Load Data\n    print(\"--- Loading Train/Val/Test Data ---\")\n    train_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'train.jsonl'))\n    val_raw   = load_jsonl_dataset(os.path.join(DATA_DIR, 'validation.jsonl'))\n    test_raw  = load_jsonl_dataset(os.path.join(DATA_DIR, 'test.jsonl'))\n    if train_raw is None or val_raw is None or test_raw is None: raise ValueError(\"Failed to load data files.\")\n    all_raw_data = train_raw + val_raw + test_raw\n\n    # 2. Preprocess ALL Data\n    print(\"\\n--- Preprocessing ALL Data ---\")\n    all_processed = preprocess_for_hybrid(all_raw_data)\n    if not all_processed: raise ValueError(\"Preprocessing failed.\")\n    score_lookup = create_score_lookup(all_processed)\n    games_data_agg = aggregate_data_by_turn(all_processed)\n    graph_lookup, player_maps_game = build_turn_graph_lookup(games_data_agg, score_lookup)\n\n    # 3. Fit Tokenizer\n    print(\"\\n--- Tokenizing Text Data ---\")\n    all_texts = [s['clean_text'] for s in all_processed]\n    tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n    tokenizer.fit_on_texts(all_texts)\n    word_index = tokenizer.word_index\n    vocab_size = min(MAX_VOCAB_SIZE, len(word_index) + 1)\n    print(f\"Actual Vocab size used: {vocab_size} (limited by MAX_VOCAB_SIZE)\")\n\n    # 4. Prepare SEPARATE Data Splits\n    print(\"\\n--- Preparing Train/Val/Test Data Splits ---\")\n    train_processed = preprocess_for_hybrid(train_raw); val_processed = preprocess_for_hybrid(val_raw); test_processed = preprocess_for_hybrid(test_raw)\n    if not train_processed or not val_processed or not test_processed: raise ValueError(\"Data splits empty.\")\n\n    def tokenize_and_pad(samples): texts=[s['clean_text'] for s in samples]; sequences=tokenizer.texts_to_sequences(texts); return pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post',truncating='post')\n    padded_train=tokenize_and_pad(train_processed); padded_val=tokenize_and_pad(val_processed); padded_test=tokenize_and_pad(test_processed)\n    print(f\"Padded Shapes: Tr={padded_train.shape}, Vl={padded_val.shape}, Ts={padded_test.shape}\")\n\n    def extract_features_labels_keys(samples): labels=np.array([s['label'] for s in samples]); delta_feats=np.array([extract_delta_features(s, score_lookup) for s in samples]); turn_keys=[(s['game_id'],s['year'],s['season']) for s in samples]; return labels, delta_feats, turn_keys\n    labels_train, delta_feats_train, turn_keys_train = extract_features_labels_keys(train_processed); labels_val, delta_feats_val, turn_keys_val = extract_features_labels_keys(val_processed); labels_test, delta_feats_test, turn_keys_test = extract_features_labels_keys(test_processed)\n\n    # 5. Apply Downsampling\n    print(\"\\n--- Downsampling Training Data ---\")\n    train_indices = np.arange(len(labels_train)); minority_indices = train_indices[labels_train == 0]; majority_indices = train_indices[labels_train == 1]\n    print(f\"Original Train counts: Lie(0)={len(minority_indices)}, Truth(1)={len(majority_indices)}\")\n    if len(minority_indices) == 0 or len(majority_indices) == 0: raise ValueError(\"Cannot downsample, empty class.\")\n    majority_downsampled_indices = resample(majority_indices, replace=False, n_samples=len(minority_indices), random_state=SEED)\n    downsampled_train_indices = np.concatenate([minority_indices, majority_downsampled_indices]); np.random.shuffle(downsampled_train_indices)\n    padded_train_ds = padded_train[downsampled_train_indices]; delta_feats_train_ds = delta_feats_train[downsampled_train_indices]; labels_train_ds = labels_train[downsampled_train_indices]; turn_keys_train_list_ds = [turn_keys_train[i] for i in downsampled_train_indices]\n    print(f\"Downsampled Train counts: Lie(0)={sum(labels_train_ds==0)}, Truth(1)={sum(labels_train_ds==1)}\")\n    print(f\"Downsampled Train Data Shapes: Text={padded_train_ds.shape}, Delta={delta_feats_train_ds.shape}, Labels={labels_train_ds.shape}\")\n\n    # 6. Load FastText Embedding Matrix\n    print(\"\\n--- Loading FastText Embeddings (Optional) ---\")\n    embedding_matrix = load_fasttext_embedding_matrix(FASTTEXT_PATH, word_index, EMBEDDING_DIM, vocab_size)\n    if embedding_matrix is None: print(\"Proceeding without pre-trained embeddings.\")\n\n    # 7. Create tf.data Datasets\n    print(\"\\n--- Creating tf.data Datasets ---\")\n    output_signature = ((tf.TensorSpec(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32), tf.TensorSpec(shape=(DELTA_FEATURE_DIM,), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, NODE_FEATURE_DIM), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, MAX_PLAYERS), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,), dtype=tf.bool)), tf.TensorSpec(shape=(), dtype=tf.int32))\n    train_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_train_ds, delta_feats_train_ds, labels_train_ds, turn_keys_train_list_ds, graph_lookup), output_signature=output_signature).shuffle(buffer_size=len(labels_train_ds)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).repeat()\n    val_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_val, delta_feats_val, labels_val, turn_keys_val, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    test_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_test, delta_feats_test, labels_test, turn_keys_test, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    print(\"Datasets created.\")\n\n    # 8. Build and Compile Model\n    print(\"\\n--- Building and Compiling LGF-RN Model ---\")\n    model = build_lgf_rn_model(vocab_size=vocab_size, max_seq_len=MAX_SEQUENCE_LENGTH, embedding_dim=EMBEDDING_DIM, lstm_units=LSTM_UNITS, delta_dim=DELTA_FEATURE_DIM, max_players=MAX_PLAYERS, node_feat_dim=NODE_FEATURE_DIM, gcn_units=GCN_UNITS, dense_units=DENSE_UNITS, final_mlp_units=FINAL_MLP_UNITS, dropout_rate=DROPOUT_RATE, rec_dropout_rate=RECURRENT_DROPOUT_RATE, embedding_matrix=embedding_matrix)\n    optimizer = AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(class_id=0, name='recall_lie'), tf.keras.metrics.Precision(class_id=0, name='precision_lie')])\n    model.summary()\n\n    # 9. Train Model\n    # [Keep Training loop as before]\n    print(\"\\n--- Starting Training ---\")\n    model_filename = \"lgf_rn_model_best_ds_fasttext.keras\"; model_path = os.path.join(OUTPUT_DIR, model_filename)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1, restore_best_weights=True, mode='min')\n    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1, save_weights_only=False)\n    steps_per_epoch_train = len(labels_train_ds) // BATCH_SIZE + (1 if len(labels_train_ds) % BATCH_SIZE != 0 else 0)\n    print(f\"Training Steps per Epoch: {steps_per_epoch_train}\")\n    history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, steps_per_epoch=steps_per_epoch_train, callbacks=[early_stopping, checkpoint], verbose=1)\n\n\n    # 10. Evaluate Model\n    # [Keep Evaluation section as before]\n    print(\"\\n--- Evaluating Model on Test Set ---\")\n    if os.path.exists(model_path):\n        print(f\"Loading best model from: {model_path}\")\n        try: model = tf.keras.models.load_model(model_path, custom_objects={'GCNLayer': GCNLayer}); print(\"Model loaded successfully.\")\n        except Exception as e: print(f\"Error loading model: {e}. Evaluating with final weights.\")\n    else: print(\"Warning: Best model checkpoint not found. Evaluating with final weights.\")\n\n    print(\"Evaluating on test dataset...\")\n    eval_results = model.evaluate(test_dataset, verbose=1, return_dict=True)\n    test_loss = eval_results['loss']; test_acc = eval_results['accuracy']; test_recall_lie = eval_results.get('recall_lie', np.nan); test_precision_lie = eval_results.get('precision_lie', np.nan)\n    print(f\"\\nTest Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc:.4f}\\nTest Recall (Lie): {test_recall_lie:.4f}\\nTest Precision (Lie): {test_precision_lie:.4f}\")\n\n    print(\"Generating predictions for detailed metrics...\")\n    y_pred_probs = model.predict(test_dataset); y_pred_bin = (y_pred_probs > 0.5).astype(int).flatten(); y_true = labels_test\n\n    if len(y_true) != len(y_pred_bin):\n         print(f\"CRITICAL WARNING: Length mismatch true labels ({len(y_true)}) vs predictions ({len(y_pred_bin)}). Recalculating labels.\")\n         y_true_list_from_ds = []\n         try:\n             for _, label_batch in test_dataset.as_numpy_iterator(): y_true_list_from_ds.extend(label_batch)\n             y_true = np.array(y_true_list_from_ds)\n             if len(y_true) > len(y_pred_bin): y_true = y_true[:len(y_pred_bin)]\n             elif len(y_true) < len(y_pred_bin): y_true= None\n         except tf.errors.OutOfRangeError: print(\"Could not recalculate labels from test_dataset (non-repeatable). Metrics will be skipped.\"); y_true = None\n\n    if y_true is not None and len(y_true) == len(y_pred_bin):\n        f1_lie = f1_score(y_true, y_pred_bin, pos_label=0, zero_division=0); f1_truth = f1_score(y_true, y_pred_bin, pos_label=1, zero_division=0); f1_macro = f1_score(y_true, y_pred_bin, average='macro', zero_division=0); f1_weighted = f1_score(y_true, y_pred_bin, average='weighted', zero_division=0)\n        print(f\"\\nF1 Score (Lie=0): {f1_lie:.4f}\\nF1 Score (Truth=1): {f1_truth:.4f}\\nMacro F1 Score: {f1_macro:.4f}\\nWeighted F1 Score: {f1_weighted:.4f}\")\n        print(\"\\nClassification Report:\"); print(classification_report(y_true, y_pred_bin, target_names=['Lie (0)', 'Truth (1)'], digits=4, zero_division=0))\n\n        # 11. Plot Confusion Matrix\n        conf_matrix = confusion_matrix(y_true, y_pred_bin); plt.figure(figsize=(6, 5))\n        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred Lie(0)', 'Pred Truth(1)'], yticklabels=['Actual Lie(0)', 'Actual Truth(1)'])\n        plt.title(f'LGF-RN Model CM\\nAcc:{test_acc:.3f}|MacroF1:{f1_macro:.3f}|Lie F1:{f1_lie:.3f}', fontsize=9); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.tight_layout()\n        plot_cm_path = os.path.join(OUTPUT_DIR, \"cm_lgf_rn_ds_fasttext.png\");\n        try: plt.savefig(plot_cm_path); print(f\"Saved CM plot: {plot_cm_path}\")\n        except Exception as e: print(f\"Error saving CM plot: {e}\")\n        # plt.show()\n    else: print(\"Could not calculate detailed metrics due to label/prediction length issues.\")\n\n    print(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T11:32:10.618415Z","iopub.execute_input":"2025-04-15T11:32:10.618787Z","iopub.status.idle":"2025-04-15T11:34:05.974820Z","shell.execute_reply.started":"2025-04-15T11:32:10.618762Z","shell.execute_reply":"2025-04-15T11:34:05.973770Z"}},"outputs":[{"name":"stdout","text":"--- Loading Train/Val/Test Data ---\n\n--- Preprocessing ALL Data ---\n Preprocessed 17289 labeled messages. (Skipped 6 dialogues due to data issues)\nCreating score lookup from 17289 samples...\nScore lookup created: 1389 unique player-turn entries found.\n  - Entries with valid scores: 1389\n  - Entries where score was NaN: 0\nAggregated samples into turns for 12 games.\nBuilding turn graph lookup (using A+I)...\nGraph lookup built: 312 turns processed.\n\n--- Tokenizing Text Data ---\nActual Vocab size used: 9946 (limited by MAX_VOCAB_SIZE)\n\n--- Preparing Train/Val/Test Data Splits ---\n Preprocessed 13132 labeled messages. (Skipped 5 dialogues due to data issues)\n Preprocessed 1416 labeled messages. (Skipped 1 dialogues due to data issues)\n Preprocessed 2741 labeled messages.\nPadded Shapes: Tr=(13132, 80), Vl=(1416, 80), Ts=(2741, 80)\n\n--- Downsampling Training Data ---\nOriginal Train counts: Lie(0)=591, Truth(1)=12541\nDownsampled Train counts: Lie(0)=591, Truth(1)=591\nDownsampled Train Data Shapes: Text=(1182, 80), Delta=(1182, 2), Labels=(1182,)\n\n--- Loading FastText Embeddings (Optional) ---\nLoading FastText vectors from: /kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\nError: FastText file not found at /kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\nProceeding without pre-trained embeddings.\n\n--- Creating tf.data Datasets ---\nDatasets created.\n\n--- Building and Compiling LGF-RN Model ---\nInitializing Embedding layer from scratch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"LGF_RN_Model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LGF_RN_Model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ token_embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │      \u001b[38;5;34m2,983,800\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_12 (\u001b[38;5;33mNotEqual\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bilstm (\u001b[38;5;33mBidirectional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m186,880\u001b[0m │ token_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                           │                        │                │ not_equal_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_6    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_dense_v (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m16,384\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_dense_q (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m16,384\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_attn_query_value      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ attn_dense_v[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mAdd\u001b[0m)                     │                        │                │ attn_dense_q[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_mask_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ tanh_attn_scores          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ add_attn_query_value[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_13 (\u001b[38;5;33mNotEqual\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_mask_to_float        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ graph_mask_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_scorer (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ tanh_attn_scores[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_text_mask_float      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ not_equal_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_nodes_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ expand_mask_dim (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ cast_mask_to_float[\u001b[38;5;34m0\u001b[0m]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ squeeze_attn_scores       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ attn_scorer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mReshape\u001b[0m)                 │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ create_mask_penalty       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ cast_text_mask_float[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mask_nodes (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ graph_nodes_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                           │                        │                │ expand_mask_dim[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_adj_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_mask_penalty_to_scor… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ squeeze_attn_scores[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mAdd\u001b[0m)                     │                        │                │ create_mask_penalty[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gcn1 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ mask_nodes[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ graph_adj_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_softmax         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ add_mask_penalty_to_s… │\n│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ gcn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ expand_attn_weights       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ attention_softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mReshape\u001b[0m)                 │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m48\u001b[0m │ delta_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gcn2 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m4,160\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ graph_adj_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ weighted_sum_context      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │ expand_attn_weights[\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ not_equal_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_dense2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m544\u001b[0m │ delta_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ gcn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concat_text_delta         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ weighted_sum_context[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ delta_dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_pooling             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │ graph_mask_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ proj_text_delta (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m20,608\u001b[0m │ concat_text_delta[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ proj_graph (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ graph_pooling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ proj_text_delta[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ proj_graph[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concat_final              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ final_mlp_dense (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m18,528\u001b[0m │ concat_final[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ final_mlp_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_prob (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m97\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ token_embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,983,800</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bilstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                           │                        │                │ not_equal_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_6    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_dense_v (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_dense_q (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_attn_query_value      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attn_dense_v[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │                        │                │ attn_dense_q[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_mask_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ tanh_attn_scores          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_attn_query_value[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_mask_to_float        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ graph_mask_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attn_scorer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ tanh_attn_scores[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_text_mask_float      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_nodes_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ expand_mask_dim (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cast_mask_to_float[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ squeeze_attn_scores       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attn_scorer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ create_mask_penalty       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cast_text_mask_float[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mask_nodes (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ graph_nodes_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                           │                        │                │ expand_mask_dim[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_adj_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_mask_penalty_to_scor… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ squeeze_attn_scores[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │                        │                │ create_mask_penalty[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gcn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ mask_nodes[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ graph_adj_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_softmax         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_mask_penalty_to_s… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ expand_attn_weights       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ delta_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gcn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ graph_adj_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ weighted_sum_context      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │ expand_attn_weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ not_equal_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ delta_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │ delta_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concat_text_delta         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ weighted_sum_context[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ delta_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ graph_pooling             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │ graph_mask_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ proj_text_delta (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ concat_text_delta[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ proj_graph (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ graph_pooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ proj_text_delta[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ proj_graph[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concat_final              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ final_mlp_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ concat_final[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ final_mlp_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,251,849\u001b[0m (12.40 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,251,849</span> (12.40 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,251,849\u001b[0m (12.40 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,251,849</span> (12.40 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n--- Starting Training ---\nTraining Steps per Epoch: 37\nEpoch 1/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.4733 - loss: 3.1798 - precision_lie: 0.4619 - recall_lie: 0.4410\nEpoch 1: val_loss improved from inf to 0.42565, saving model to /kaggle/working/lgf_rn_model_best_ds_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 292ms/step - accuracy: 0.4735 - loss: 3.1628 - precision_lie: 0.4624 - recall_lie: 0.4422 - val_accuracy: 0.9244 - val_loss: 0.4257 - val_precision_lie: 0.9590 - val_recall_lie: 0.9625\nEpoch 2/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.4976 - loss: 1.4409 - precision_lie: 0.4932 - recall_lie: 0.5086\nEpoch 2: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.4975 - loss: 1.4377 - precision_lie: 0.4932 - recall_lie: 0.5070 - val_accuracy: 0.9025 - val_loss: 0.4544 - val_precision_lie: 0.9594 - val_recall_lie: 0.9382\nEpoch 3/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5337 - loss: 1.0040 - precision_lie: 0.5327 - recall_lie: 0.5280\nEpoch 3: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.5341 - loss: 1.0019 - precision_lie: 0.5331 - recall_lie: 0.5278 - val_accuracy: 0.7168 - val_loss: 0.6354 - val_precision_lie: 0.9678 - val_recall_lie: 0.7294\nEpoch 4/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.5685 - loss: 0.8150 - precision_lie: 0.5549 - recall_lie: 0.4968\nEpoch 4: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.5688 - loss: 0.8136 - precision_lie: 0.5558 - recall_lie: 0.4973 - val_accuracy: 0.6292 - val_loss: 0.6724 - val_precision_lie: 0.9696 - val_recall_lie: 0.6338\nEpoch 5/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6409 - loss: 0.6744 - precision_lie: 0.6560 - recall_lie: 0.5931\nEpoch 5: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.6416 - loss: 0.6733 - precision_lie: 0.6566 - recall_lie: 0.5940 - val_accuracy: 0.6299 - val_loss: 0.6943 - val_precision_lie: 0.9634 - val_recall_lie: 0.6390\nEpoch 6/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7750 - loss: 0.4936 - precision_lie: 0.7684 - recall_lie: 0.7728\nEpoch 6: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.7753 - loss: 0.4934 - precision_lie: 0.7690 - recall_lie: 0.7729 - val_accuracy: 0.6066 - val_loss: 0.8461 - val_precision_lie: 0.9652 - val_recall_lie: 0.6125\nEpoch 7/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8439 - loss: 0.3565 - precision_lie: 0.8302 - recall_lie: 0.8579\nEpoch 7: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.8438 - loss: 0.3568 - precision_lie: 0.8304 - recall_lie: 0.8576 - val_accuracy: 0.5939 - val_loss: 0.9092 - val_precision_lie: 0.9645 - val_recall_lie: 0.5993\nEpoch 8/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8872 - loss: 0.2684 - precision_lie: 0.8880 - recall_lie: 0.8849\nEpoch 8: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 203ms/step - accuracy: 0.8875 - loss: 0.2680 - precision_lie: 0.8882 - recall_lie: 0.8852 - val_accuracy: 0.5417 - val_loss: 1.3946 - val_precision_lie: 0.9659 - val_recall_lie: 0.5419\nEpoch 9/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9267 - loss: 0.2003 - precision_lie: 0.9093 - recall_lie: 0.9446\nEpoch 9: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 221ms/step - accuracy: 0.9270 - loss: 0.1993 - precision_lie: 0.9099 - recall_lie: 0.9447 - val_accuracy: 0.5579 - val_loss: 1.6478 - val_precision_lie: 0.9657 - val_recall_lie: 0.5596\nEpoch 10/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9641 - loss: 0.1012 - precision_lie: 0.9612 - recall_lie: 0.9656\nEpoch 10: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.9639 - loss: 0.1017 - precision_lie: 0.9608 - recall_lie: 0.9657 - val_accuracy: 0.5148 - val_loss: 2.0316 - val_precision_lie: 0.9719 - val_recall_lie: 0.5096\nEpoch 11/60\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9748 - loss: 0.0718 - precision_lie: 0.9810 - recall_lie: 0.9678\nEpoch 11: val_loss did not improve from 0.42565\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9746 - loss: 0.0724 - precision_lie: 0.9809 - recall_lie: 0.9675 - val_accuracy: 0.5805 - val_loss: 1.9897 - val_precision_lie: 0.9682 - val_recall_lie: 0.5824\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 1.\n\n--- Evaluating Model on Test Set ---\nLoading best model from: /kaggle/working/lgf_rn_model_best_ds_fasttext.keras\nError loading model: The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().. Evaluating with final weights.\nEvaluating on test dataset...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8603 - loss: 0.5033 - precision_lie: 0.9353 - recall_lie: 0.9140\n\nTest Loss: 0.4936\nTest Accuracy: 0.8395\nTest Recall (Lie): 0.9124\nTest Precision (Lie): 0.9117\nGenerating predictions for detailed metrics...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step\n\nF1 Score (Lie=0): 0.0795\nF1 Score (Truth=1): 0.9121\nMacro F1 Score: 0.4958\nWeighted F1 Score: 0.8392\n\nClassification Report:\n              precision    recall  f1-score   support\n\n     Lie (0)     0.0798    0.0792    0.0795       240\n   Truth (1)     0.9117    0.9124    0.9121      2501\n\n    accuracy                         0.8395      2741\n   macro avg     0.4958    0.4958    0.4958      2741\nweighted avg     0.8389    0.8395    0.8392      2741\n\nSaved CM plot: /kaggle/working/cm_lgf_rn_ds_fasttext.png\n\n--- Script Finished ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport re\nimport string\nimport glob\nimport warnings\nimport random\nimport time\nimport requests\nimport zipfile\n\n# Scikit-learn imports\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.utils import resample\n\n# TensorFlow / Keras imports\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, Embedding, Dense, Dropout, Concatenate,\n                                     Layer, MultiHeadAttention, LayerNormalization,\n                                     GlobalAveragePooling1D, Add, Reshape,\n                                     Multiply, Lambda)\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# --- Constants and Configuration ---\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Data/Model Paths\nBASE_DATA_DIR = './Dataset/'\nKAGGLE_DATA_DIR = '/kaggle/input/diplomacy/transformers/default/1/Dataset/'\nif os.path.exists(KAGGLE_DATA_DIR): BASE_DATA_DIR = KAGGLE_DATA_DIR\nDATA_DIR = os.path.join(BASE_DATA_DIR, 'data')\nOUTPUT_DIR = '/kaggle/working/' if os.path.exists('/kaggle/working/') else './output/'\nFASTTEXT_PATH = '/kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Model Hyperparameters\nMAX_SEQUENCE_LENGTH = 60\nMAX_VOCAB_SIZE = 10000\nEMBEDDING_DIM = 300\nNODE_FEATURE_DIM = 1\nDELTA_FEATURE_DIM = 2\nMAX_PLAYERS = 7\nNUM_HEADS_TXT=4\nNUM_HEADS_REASON=4\nGCN_UNITS=64\nDROPOUT_RATE_ENCODER = 0.15\nDROPOUT_RATE_FUSION = 0.4\n\n# Training Hyperparameters\nLEARNING_RATE = 8e-5\nWEIGHT_DECAY = 1e-4\nBATCH_SIZE = 32\nEPOCHS = 50\nPATIENCE = 10\n\n# --- Helper Functions ---\n# [Keep load_jsonl_dataset, clean_text, preprocess_for_hybrid, create_score_lookup,\n#  get_next_turn, extract_delta_features, aggregate_data_by_turn, build_turn_graph_lookup]\ndef load_jsonl_dataset(file_path):\n    data = []\n    skipped_lines = 0\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f):\n                try: data.append(json.loads(line))\n                except json.JSONDecodeError: skipped_lines += 1\n    except FileNotFoundError: print(f\"Error: File not found at {file_path}\"); return None\n    if skipped_lines > 0: print(f\"Warn: Skipped {skipped_lines} invalid JSON lines in {file_path}\")\n    return data\n\ndef clean_text(text):\n    if not isinstance(text, str): return \"\"\n    text = text.lower(); text = re.sub(r'http\\S+|@\\w+|#\\w+', '', text)\n    text = text.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\")))\n    text = re.sub(r'\\d+', '', text); text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef preprocess_for_hybrid(data_raw):\n    processed_samples = []; skipped_dialogues=0\n    if data_raw is None: return processed_samples\n    for dialogue_idx, dialogue_sample in enumerate(data_raw):\n        game_id=dialogue_sample.get('game_id'); messages=dialogue_sample.get('messages',[]); speakers=dialogue_sample.get('speakers',[]); recipients=dialogue_sample.get('receivers',[])\n        years=dialogue_sample.get('years',[]); seasons=dialogue_sample.get('seasons',[]); sender_labels=dialogue_sample.get('sender_labels',[]); game_scores=dialogue_sample.get('game_score',[]); game_score_deltas=dialogue_sample.get('game_score_delta',[])\n        list_len=len(messages)\n        required_lists = [speakers, recipients, years, seasons, sender_labels, game_scores, game_score_deltas]\n        if not (game_id and list_len > 0 and sender_labels is not None and all(isinstance(lst, list) and len(lst) == list_len for lst in required_lists if lst is not None)):\n             skipped_dialogues+=1; continue\n        for i in range(list_len):\n            label=-1; score_num=np.nan; delta_num=np.nan\n            if isinstance(sender_labels, list) and i < len(sender_labels):\n                if sender_labels[i] is False: label=0\n                elif sender_labels[i] is True: label=1\n            else: continue\n            try:\n                if game_scores and i < len(game_scores) and game_scores[i] is not None: score_num=float(game_scores[i])\n            except (ValueError, TypeError): pass\n            try:\n                if game_score_deltas and i < len(game_score_deltas) and game_score_deltas[i] is not None: delta_num=float(game_score_deltas[i])\n            except (ValueError, TypeError): pass\n            if label != -1:\n                processed_delta = delta_num if pd.notna(delta_num) else 0.0\n                processed_samples.append({'text': messages[i] if messages and i < len(messages) else \"\", 'clean_text': clean_text(messages[i] if messages and i < len(messages) else \"\"), 'label': label, 'game_id': game_id, 'year': str(years[i] if years and i < len(years) else 'unknown'), 'season': str(seasons[i] if seasons and i < len(seasons) else 'unknown').lower(), 'speaker': str(speakers[i] if speakers and i < len(speakers) else 'unknown').lower(), 'recipient': str(recipients[i] if recipients and i < len(recipients) else 'unknown').lower(), 'score_numeric': score_num, 'delta_numeric': processed_delta})\n    print(f\" Preprocessed {len(processed_samples)} labeled messages.\", end=\"\")\n    if skipped_dialogues > 0: print(f\" (Skipped {skipped_dialogues} dialogues)\", end=\"\")\n    print()\n    return processed_samples\n\ndef create_score_lookup(all_samples):\n    score_lookup=defaultdict(lambda:np.nan); processed_keys=set(); valid_scores=0; skipped_no_score=0\n    print(f\"Creating score lookup from {len(all_samples)} samples...\")\n    for sample in all_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); player=sample.get('speaker'); score_num=sample.get('score_numeric')\n        if game_id is not None and year!='unknown' and season!='unknown' and player!='unknown':\n            key=(game_id,year,season,player)\n            if key not in processed_keys:\n                if pd.notna(score_num): score_lookup[key]=score_num; valid_scores+=1\n                else: skipped_no_score+=1\n                processed_keys.add(key)\n    print(f\"Score lookup created: {len(score_lookup)} entries ({valid_scores} unique). Skipped N/A: {skipped_no_score}.\")\n    return score_lookup\n\ndef get_next_turn(current_year_str, current_season_str):\n    \"\"\"Calculates the next game turn (year, season).\"\"\"\n    try:\n        # Operations that might fail go inside the try block\n        current_year = int(current_year_str)\n        current_season = str(current_season_str).lower() # Ensure lowercase string\n\n        # Logic based on correctly parsed values\n        if current_season == 'spring':\n            return str(current_year), 'fall'\n        elif current_season == 'fall':\n            return str(current_year), 'winter'\n        elif current_season == 'winter':\n            return str(current_year + 1), 'spring'\n        else:\n            # Handle unknown seasons gracefully\n            # print(f\"Warning: Unknown season '{current_season_str}'\") # Optional warning\n            return None, None\n    except (ValueError, TypeError):\n        # Handle errors during int() conversion or if inputs are not strings\n        # print(f\"Warning: Could not parse year '{current_year_str}' or season '{current_season_str}'\") # Optional warning\n        return None, None\n\ndef extract_delta_features(sample_info, score_lookup):\n    current_delta = sample_info.get('delta_numeric', 0.0); future_delta = 0.0\n    game_id=sample_info.get('game_id'); year=sample_info.get('year'); season=sample_info.get('season'); speaker=sample_info.get('speaker'); recipient=sample_info.get('recipient')\n    if game_id is not None and year!='unknown' and season!='unknown' and speaker!='unknown' and recipient!='unknown':\n        next_year, next_season = get_next_turn(year, season)\n        if next_year and next_season:\n            fut_spk_score = score_lookup.get((game_id, next_year, next_season, speaker), np.nan); fut_rec_score = score_lookup.get((game_id, next_year, next_season, recipient), np.nan)\n            if pd.notna(fut_spk_score) and pd.notna(fut_rec_score):\n                try: future_delta = float(fut_spk_score) - float(fut_rec_score)\n                except (ValueError, TypeError): future_delta = 0.0\n    return np.array([current_delta, future_delta], dtype=np.float32)\n\ndef aggregate_data_by_turn(all_processed_samples):\n    games_data = defaultdict(lambda: defaultdict(lambda: {'messages': [], 'players': set()}))\n    for sample in all_processed_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); speaker=sample.get('speaker'); recipient=sample.get('recipient')\n        if game_id is None or year=='unknown' or season=='unknown': continue\n        turn_key=(year,season); player_set = set()\n        if speaker is not None and speaker != 'unknown': player_set.add(speaker)\n        if recipient is not None and recipient != 'unknown': player_set.add(recipient)\n        if player_set: games_data[game_id][turn_key]['players'].update(player_set); games_data[game_id][turn_key]['messages'].append({'speaker':speaker,'recipient':recipient})\n    print(f\"Aggregated samples into turns for {len(games_data)} games.\")\n    return games_data\n\ndef build_turn_graph_lookup(games_data_agg, score_lookup):\n    print(\"Building turn graph lookup (using A+I)...\"); graph_lookup={}; player_maps_game={}\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); default_A = np.identity(MAX_PLAYERS, dtype=np.float32); default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}; skipped_games_players = 0; processed_turns = 0\n    for game_id, turns in games_data_agg.items():\n        all_p_in_game = set();\n        for turn_data in turns.values(): valid_players_in_turn = {p for p in turn_data['players'] if p is not None and p != 'unknown'}; all_p_in_game.update(valid_players_in_turn)\n        if not all_p_in_game: skipped_games_players += 1; continue\n        sorted_p = sorted(list(all_p_in_game)); num_p_game = len(sorted_p)\n        if num_p_game > MAX_PLAYERS: sorted_p = sorted_p[:MAX_PLAYERS]; num_p_game = MAX_PLAYERS\n        p2i = {p: i for i, p in enumerate(sorted_p)}; player_maps_game[game_id] = p2i\n        for (yr, sn), t_data in turns.items():\n            tk = (game_id, yr, sn); X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); M = np.zeros(MAX_PLAYERS, dtype=bool); Ab = np.zeros((MAX_PLAYERS, MAX_PLAYERS), dtype=np.float32)\n            current_turn_players = {p for p in t_data['players'] if p is not None and p != 'unknown'}\n            for p in current_turn_players:\n                idx = p2i.get(p)\n                if idx is not None: score = score_lookup.get((game_id, yr, sn, p), np.nan); X[idx, 0] = 0.0 if pd.isna(score) else float(score); M[idx] = True\n            for msg in t_data['messages']: i_s = p2i.get(msg.get('speaker')); i_r = p2i.get(msg.get('recipient'));\n            if i_s is not None and i_r is not None and i_s != i_r: Ab[i_s, i_r] = 1.0; Ab[i_r, i_s] = 1.0\n            Asl = Ab + np.identity(MAX_PLAYERS, dtype=np.float32); graph_lookup[tk] = {'X': X, 'A': Asl, 'M': M}; processed_turns += 1\n    print(f\"Graph lookup built: {processed_turns} turns processed.\")\n    if skipped_games_players > 0: print(f\"Skipped {skipped_games_players} games.\")\n    return graph_lookup, player_maps_game\n\n# --- GCN Layer Definition ---\nclass GCNLayer(layers.Layer):\n    def __init__(self, units, activation=None, name=None, **kwargs): super().__init__(name=name, **kwargs); self.units = units; self.activation = tf.keras.activations.get(activation)\n    def build(self, input_shape): node_feature_shape = tf.TensorShape(input_shape[0]); node_dim = int(node_feature_shape[-1]); self.w = self.add_weight(shape=(node_dim, self.units), initializer='glorot_uniform', name='w', trainable=True); self.b = self.add_weight(shape=(self.units,), initializer='zeros', name='b', trainable=True); super().build(input_shape)\n    def call(self, inputs):\n        node_features, adj_matrix = inputs\n        support = tf.matmul(node_features, self.w)\n        output = tf.matmul(adj_matrix, support)\n        output = output + self.b\n        if self.activation is not None:\n            output = self.activation(output)\n        # CORRECTED return statement indentation\n        return output\n    def compute_output_shape(self, input_shape): node_feature_shape = tf.TensorShape(input_shape[0]); batch_size = node_feature_shape[0]; num_nodes = node_feature_shape[1]; return tf.TensorShape((batch_size, num_nodes, self.units))\n    def get_config(self): config = super().get_config(); config.update({\"units\": self.units, \"activation\": tf.keras.activations.serialize(self.activation)}); return config\n    @classmethod\n    def from_config(cls, config): activation_config = config.pop(\"activation\", None); activation = tf.keras.activations.deserialize(activation_config) if activation_config else None; config['activation'] = activation; return cls(**config)\n\n\n# --- Baseline Model Classes ---\n# [Keep TextFeatureEncoder, GraphEncoder, DiplomacyHybridModel classes as before,\n#  ensuring GraphEncoder has compute_output_shape and uses Keras layers for TF ops]\nclass TextFeatureEncoder(Model):\n    def __init__(self, max_vocab_size, embedding_dim, seq_len, num_heads, dropout_rate, delta_feature_dim, embedding_matrix=None, name=\"text_feature_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.seq_len = seq_len; self.delta_feature_dim = delta_feature_dim;\n        if embedding_matrix is not None: print(\"Initializing TextFeatureEncoder Embedding with pre-trained weights.\"); self.embedding=layers.Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=seq_len, weights=[embedding_matrix], trainable=True, name='embedding')\n        else: print(\"Initializing TextFeatureEncoder Embedding from scratch.\"); self.embedding=layers.Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=seq_len, trainable=True, name='embedding')\n        self.mha=layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, name='attention'); self.add_norm1=layers.Add(name='add_resid_1'); self.layernorm1=layers.LayerNormalization(epsilon=1e-6, name='norm_1'); self.pooling=layers.GlobalAveragePooling1D(name='text_pooling'); self.dropout_text1=layers.Dropout(dropout_rate, name='text_dropout_1'); self.dense_features=layers.Dense(16, activation='relu', name='dense_delta_features'); self.concatenate=layers.Concatenate(name='concat_text_features'); self.dropout_combined=layers.Dropout(dropout_rate*1.5, name='text_feature_dropout'); self.output_dim = embedding_dim; self.output_dense=layers.Dense(self.output_dim, activation='relu', name='text_feature_output')\n    def call(self, inputs, training=False): text_input, feature_input = inputs; x_txt = self.embedding(text_input); attn_output = self.mha(query=x_txt, value=x_txt, key=x_txt, training=training); x_txt = self.add_norm1([x_txt, attn_output]); x_txt = self.layernorm1(x_txt); text_emb = self.pooling(x_txt); text_emb = self.dropout_text1(text_emb, training=training); feature_proc = self.dense_features(feature_input); combined = self.concatenate([text_emb, feature_proc]); combined_dropout = self.dropout_combined(combined, training=training); output_embedding = self.output_dense(combined_dropout); return output_embedding\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, self.output_dim))\n    def get_config(self): config=super().get_config(); config.update({'max_vocab_size':self.embedding.input_dim, 'embedding_dim':self.embedding.output_dim, 'seq_len': self.seq_len, 'num_heads':self.mha.num_heads,'dropout_rate':self.dropout_text1.rate, 'delta_feature_dim': self.delta_feature_dim}); config.pop('embedding_matrix', None); return config\n    @classmethod\n    def from_config(cls, config): return cls(**config)\n\nclass GraphEncoder(Model):\n    def __init__(self, max_players, node_feature_dim, gcn_units, dropout_rate, final_emb_dim, name=\"graph_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.max_players=max_players; self.final_emb_dim=final_emb_dim; self.node_feature_dim=node_feature_dim; self.gcn_units = gcn_units;\n        self.cast_mask = layers.Lambda(lambda x: tf.cast(x, dtype=tf.float32), name='cast_mask_to_float_ge'); self.expand_mask = layers.Reshape((max_players, 1), name='expand_mask_dim_ge'); self.mask_mult = layers.Multiply(name='mask_nodes_ge'); self.gcn1=GCNLayer(gcn_units, activation='relu', name='CustomGCN1'); self.dropout_gcn1=layers.Dropout(dropout_rate, name='dropout_gcn1'); self.gcn2=GCNLayer(gcn_units, activation='relu', name='CustomGCN2'); self.dropout_gcn2=layers.Dropout(dropout_rate, name='dropout_gcn2'); self.gcn3=GCNLayer(gcn_units // 2, activation='relu', name='CustomGCN3'); self.dropout_gcn3=layers.Dropout(dropout_rate, name='dropout_gcn3'); self.graph_pooling=layers.GlobalAveragePooling1D(name='GraphPooling'); self.dropout_pooled=layers.Dropout(dropout_rate * 1.5, name='dropout_pooled'); self.output_dense=layers.Dense(self.final_emb_dim, activation='relu', name='graph_output')\n    def call(self, inputs, training=False): node_features, adj_matrix, node_mask = inputs; node_mask_float=self.cast_mask(node_mask); node_mask_expanded=self.expand_mask(node_mask_float); masked_node_features=self.mask_mult([node_features, node_mask_expanded]); x_graph = self.gcn1([masked_node_features, adj_matrix]); x_graph = self.dropout_gcn1(x_graph, training=training); x_graph = self.gcn2([x_graph, adj_matrix]); x_graph = self.dropout_gcn2(x_graph, training=training); x_graph = self.gcn3([x_graph, adj_matrix]); x_graph = self.dropout_gcn3(x_graph, training=training); graph_emb_pooled = self.graph_pooling(x_graph, mask=node_mask); graph_emb_pooled = self.dropout_pooled(graph_emb_pooled, training=training); graph_embedding = self.output_dense(graph_emb_pooled); return graph_embedding\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, self.final_emb_dim))\n    def get_config(self): config = super().get_config(); config.update({'max_players':self.max_players, 'node_feature_dim':self.node_feature_dim, 'gcn_units':self.gcn_units, 'dropout_rate':self.dropout_gcn1.rate, 'final_emb_dim':self.final_emb_dim}); return config\n    @classmethod\n    def from_config(cls, config, custom_objects=None): return cls(**config)\n\nclass DiplomacyHybridModel(Model):\n    def __init__(self, text_feature_encoder, graph_encoder, reason_dropout_rate, attention_heads, name=\"diplomacy_hybrid\", **kwargs):\n        super().__init__(name=name, **kwargs); self.text_feature_encoder = text_feature_encoder; self.graph_encoder = graph_encoder; self.concatenate = layers.Concatenate(name='combine_embeddings')\n        try: text_out_dim = text_feature_encoder.output_dim; graph_out_dim = graph_encoder.final_emb_dim\n        except AttributeError: text_out_dim = EMBEDDING_DIM; graph_out_dim = EMBEDDING_DIM // 2\n        combined_dim = text_out_dim + graph_out_dim\n        self.reason_dropout_rate = reason_dropout_rate; self.attention_heads = attention_heads;\n        self.reason_dense1 = layers.Dense(combined_dim, activation='relu', name='reason_dense1'); self.dropout_reason1 = layers.Dropout(self.reason_dropout_rate, name='dropout_reason1'); self.reshape_for_attn = layers.Reshape((1, combined_dim)); attn_key_dim = max(16, combined_dim // self.attention_heads); self.attention_reason = layers.MultiHeadAttention(num_heads=self.attention_heads, key_dim=attn_key_dim, name='reason_attention'); self.reshape_after_attn = layers.Reshape((combined_dim,)); self.dropout_reason2 = layers.Dropout(self.reason_dropout_rate, name='dropout_reason2'); self.output_classifier = layers.Dense(1, activation='sigmoid', name='final_output')\n    def call(self, inputs, training=False): text_input, feature_input, node_features, adj_matrix, node_mask = inputs; text_feat_emb = self.text_feature_encoder([text_input, feature_input], training=training); graph_emb = self.graph_encoder([node_features, adj_matrix, node_mask], training=training); combined = self.concatenate([text_feat_emb, graph_emb]); x = self.reason_dense1(combined); x = self.dropout_reason1(x, training=training); x_reshaped = self.reshape_for_attn(x); attn_output = self.attention_reason(query=x_reshaped, value=x_reshaped, key=x_reshaped, training=training); x = self.reshape_after_attn(attn_output); x = self.dropout_reason2(x, training=training); output = self.output_classifier(x); return output\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, 1)) # Output is single logit/probability\n    def get_config(self): config = super().get_config(); config.update({\"text_feature_encoder_config\": self.text_feature_encoder.get_config(), \"graph_encoder_config\": self.graph_encoder.get_config(), \"reason_dropout_rate\": self.reason_dropout_rate, \"attention_heads\": self.attention_heads}); config.pop(\"text_feature_encoder\", None); config.pop(\"graph_encoder\", None); return config\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        text_encoder_config = config.pop(\"text_feature_encoder_config\"); graph_encoder_config = config.pop(\"graph_encoder_config\")\n        text_encoder = TextFeatureEncoder.from_config(text_encoder_config, custom_objects=custom_objects)\n        graph_encoder = GraphEncoder.from_config(graph_encoder_config, custom_objects=custom_objects)\n        return cls(text_feature_encoder=text_encoder, graph_encoder=graph_encoder, **config)\n\n\n# --- FastText Loading Function ---\n# [Keep the FastText loading function as before]\ndef load_fasttext_embedding_matrix(filepath, word_index, embedding_dim, max_vocab_size):\n    print(f\"Loading FastText vectors from: {filepath}\")\n    if not os.path.exists(filepath): print(f\"Error: FastText file not found at {filepath}\"); return None\n    start_time = time.time(); embeddings_index = {}; skipped_lines = 0; skipped_dims = 0\n    try:\n        with open(filepath, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n            for i, line in enumerate(f):\n                if i == 0 and len(line.split()) == 2:\n                    try: int(line.split()[0]); continue\n                    except ValueError: pass\n                values = line.split(); word = values[0]\n                try:\n                    coefs = np.asarray(values[1:], dtype='float32')\n                    if len(coefs) == embedding_dim: embeddings_index[word] = coefs\n                    else: skipped_dims += 1\n                except ValueError: skipped_lines += 1; continue\n    except Exception as e: print(f\"An error occurred: {e}\"); return None\n    load_time = time.time() - start_time; print(f\"Found {len(embeddings_index)} vectors in {load_time:.2f}s.\")\n    if skipped_lines > 0: print(f\"  Skipped {skipped_lines} lines (parsing).\")\n    if skipped_dims > 0: print(f\"  Skipped {skipped_dims} words (dimension mismatch).\")\n    num_tokens = min(max_vocab_size, len(word_index) + 1); hits = 0; misses = 0\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n    for word, i in word_index.items():\n        if i >= num_tokens: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector; hits += 1\n        else: misses += 1\n    print(f\"Prepared embedding matrix: Shape {embedding_matrix.shape}\"); print(f\"  Converted {hits} words ({misses} misses).\")\n    return embedding_matrix\n\n# --- Data Generator Function ---\n# [Keep the Data Generator function as before]\ndef data_generator_split(text_padded_arr, delta_feats_arr, labels_arr, turn_keys_list, graph_lookup):\n    num_samples = len(labels_arr); indices = np.arange(num_samples)\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); default_A = np.identity(MAX_PLAYERS, dtype=np.float32); default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}\n    for i in indices:\n        text_pad = text_padded_arr[i]; delta_f = delta_feats_arr[i]; label = labels_arr[i]; turn_key = turn_keys_list[i]\n        graph_data = graph_lookup.get(turn_key, default_graph)\n        X_g = graph_data.get('X', default_graph['X']); A_g = graph_data.get('A', default_graph['A']); M_g = graph_data.get('M', default_graph['M'])\n        if X_g.shape != (MAX_PLAYERS, NODE_FEATURE_DIM) or A_g.shape != (MAX_PLAYERS, MAX_PLAYERS) or M_g.shape != (MAX_PLAYERS,):\n            X_g, A_g, M_g = default_graph['X'], default_graph['A'], default_graph['M']\n        yield (text_pad, delta_f, X_g, A_g, M_g), label\n\n# --- Main Training Script ---\nif __name__ == \"__main__\":\n    # [Keep Steps 1-7]\n    # 1. Load Data\n    print(\"--- Loading Train/Val/Test Data ---\")\n    train_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'train.jsonl')); val_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'validation.jsonl')); test_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'test.jsonl'))\n    if train_raw is None or val_raw is None or test_raw is None: raise ValueError(\"Failed data loading.\")\n    all_raw_data = train_raw + val_raw + test_raw\n\n    # 2. Preprocess ALL Data\n    print(\"\\n--- Preprocessing ALL Data ---\")\n    all_processed = preprocess_for_hybrid(all_raw_data);\n    if not all_processed: raise ValueError(\"Preprocessing failed.\")\n    score_lookup = create_score_lookup(all_processed)\n    games_data_agg = aggregate_data_by_turn(all_processed)\n    graph_lookup, player_maps_game = build_turn_graph_lookup(games_data_agg, score_lookup)\n\n    # 3. Fit Tokenizer\n    print(\"\\n--- Tokenizing Text Data ---\")\n    all_texts = [s['clean_text'] for s in all_processed]\n    tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n    tokenizer.fit_on_texts(all_texts); word_index = tokenizer.word_index\n    vocab_size = min(MAX_VOCAB_SIZE, len(word_index) + 1)\n    print(f\"Actual Vocab size used: {vocab_size}\")\n\n    # 4. Prepare SEPARATE Data Splits\n    print(\"\\n--- Preparing Train/Val/Test Data Splits ---\")\n    train_processed = preprocess_for_hybrid(train_raw); val_processed = preprocess_for_hybrid(val_raw); test_processed = preprocess_for_hybrid(test_raw)\n    if not train_processed or not val_processed or not test_processed: raise ValueError(\"Data splits empty.\")\n    def tokenize_and_pad(samples): texts=[s['clean_text'] for s in samples]; sequences=tokenizer.texts_to_sequences(texts); return pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post',truncating='post')\n    padded_train=tokenize_and_pad(train_processed); padded_val=tokenize_and_pad(val_processed); padded_test=tokenize_and_pad(test_processed)\n    print(f\"Padded Shapes: Tr={padded_train.shape}, Vl={padded_val.shape}, Ts={padded_test.shape}\")\n    def extract_features_labels_keys(samples): labels=np.array([s['label'] for s in samples]); delta_feats=np.array([extract_delta_features(s, score_lookup) for s in samples]); turn_keys=[(s['game_id'],s['year'],s['season']) for s in samples]; return labels, delta_feats, turn_keys\n    labels_train, delta_feats_train, turn_keys_train = extract_features_labels_keys(train_processed); labels_val, delta_feats_val, turn_keys_val = extract_features_labels_keys(val_processed); labels_test, delta_feats_test, turn_keys_test = extract_features_labels_keys(test_processed)\n\n    # 5. Apply Downsampling\n    print(\"\\n--- Downsampling Training Data ---\")\n    train_indices = np.arange(len(labels_train)); minority_indices = train_indices[labels_train == 0]; majority_indices = train_indices[labels_train == 1]\n    print(f\"Original Train counts: Lie(0)={len(minority_indices)}, Truth(1)={len(majority_indices)}\")\n    if len(minority_indices) == 0 or len(majority_indices) == 0: raise ValueError(\"Cannot downsample.\")\n    majority_downsampled_indices = resample(majority_indices, replace=False, n_samples=len(minority_indices), random_state=SEED)\n    downsampled_train_indices = np.concatenate([minority_indices, majority_downsampled_indices]); np.random.shuffle(downsampled_train_indices)\n    padded_train_ds = padded_train[downsampled_train_indices]; delta_feats_train_ds = delta_feats_train[downsampled_train_indices]; labels_train_ds = labels_train[downsampled_train_indices]; turn_keys_train_list_ds = [turn_keys_train[i] for i in downsampled_train_indices]\n    print(f\"Downsampled Train counts: Lie(0)={sum(labels_train_ds==0)}, Truth(1)={sum(labels_train_ds==1)}\")\n    print(f\"Downsampled Shapes: Text={padded_train_ds.shape}, Delta={delta_feats_train_ds.shape}, Labels={labels_train_ds.shape}\")\n\n    # 6. Load FastText Embedding Matrix\n    print(\"\\n--- Loading FastText Embeddings ---\")\n    embedding_matrix = load_fasttext_embedding_matrix(FASTTEXT_PATH, word_index, EMBEDDING_DIM, vocab_size)\n    if embedding_matrix is None: print(\"Proceeding without pre-trained embeddings.\")\n\n    # 7. Create tf.data Datasets\n    print(\"\\n--- Creating tf.data Datasets ---\")\n    output_signature = ((tf.TensorSpec(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32), tf.TensorSpec(shape=(DELTA_FEATURE_DIM,), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, NODE_FEATURE_DIM), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, MAX_PLAYERS), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,), dtype=tf.bool)), tf.TensorSpec(shape=(), dtype=tf.int32))\n    train_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_train_ds, delta_feats_train_ds, labels_train_ds, turn_keys_train_list_ds, graph_lookup), output_signature=output_signature).shuffle(buffer_size=len(labels_train_ds)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).repeat()\n    val_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_val, delta_feats_val, labels_val, turn_keys_val, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    test_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_test, delta_feats_test, labels_test, turn_keys_test, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    print(\"Datasets created.\")\n\n    # 8. Build & Compile Model\n    print(\"\\n--- Building and Compiling Baseline Hybrid Model (FastText, Tuned) ---\")\n    text_encoder = TextFeatureEncoder(max_vocab_size=vocab_size, embedding_dim=EMBEDDING_DIM, seq_len=MAX_SEQUENCE_LENGTH, num_heads=NUM_HEADS_TXT, dropout_rate=DROPOUT_RATE_ENCODER, delta_feature_dim=DELTA_FEATURE_DIM, embedding_matrix=embedding_matrix)\n    graph_encoder = GraphEncoder(max_players=MAX_PLAYERS, node_feature_dim=NODE_FEATURE_DIM, gcn_units=GCN_UNITS, dropout_rate=DROPOUT_RATE_ENCODER, final_emb_dim=EMBEDDING_DIM // 2)\n    diplomacy_model = DiplomacyHybridModel(text_feature_encoder=text_encoder, graph_encoder=graph_encoder, reason_dropout_rate=DROPOUT_RATE_FUSION, attention_heads=NUM_HEADS_REASON)\n    optimizer = AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    diplomacy_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(class_id=0, name='recall_lie'), tf.keras.metrics.Precision(class_id=0, name='precision_lie')])\n    # Build model explicitly - Use shapes from dataset signature\n    input_shapes_only = [spec.shape for spec in output_signature[0]]\n    diplomacy_model.build(input_shape=input_shapes_only) # Build model with input shapes\n    diplomacy_model.summary(expand_nested=True) # Now summary should work\n\n    # 9. Train Model\n    # [Keep Training loop as before]\n    print(\"\\n--- Starting Training ---\")\n    model_filename = \"baseline_hybrid_tuned_fasttext.keras\"; model_path = os.path.join(OUTPUT_DIR, model_filename)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1, restore_best_weights=True, mode='min')\n    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1, save_weights_only=False)\n    steps_per_epoch_train = len(labels_train_ds) // BATCH_SIZE + (1 if len(labels_train_ds) % BATCH_SIZE != 0 else 0)\n    print(f\"Training Steps per Epoch: {steps_per_epoch_train}\")\n    history = diplomacy_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, steps_per_epoch=steps_per_epoch_train, callbacks=[early_stopping, checkpoint], verbose=1)\n\n\n    # 10. Evaluate Model\n    # [Keep Evaluation section as before]\n    print(\"\\n--- Evaluating Model on Test Set ---\")\n    if os.path.exists(model_path):\n        print(f\"Loading best model from: {model_path}\")\n        try:\n            custom_objects = {'TextFeatureEncoder': TextFeatureEncoder, 'GraphEncoder': GraphEncoder, 'GCNLayer': GCNLayer, 'DiplomacyHybridModel': DiplomacyHybridModel}\n            model = tf.keras.models.load_model(model_path, custom_objects=custom_objects); print(\"Model loaded successfully.\")\n        except Exception as e: print(f\"Error loading model: {e}. Evaluating with final weights.\"); model = diplomacy_model\n    else: print(\"Warning: Best model checkpoint not found.\"); model = diplomacy_model\n\n    print(\"Evaluating on test dataset...\"); eval_results = model.evaluate(test_dataset, verbose=1, return_dict=True)\n    test_loss = eval_results['loss']; test_acc = eval_results['accuracy']; test_recall_lie = eval_results.get('recall_lie', np.nan); test_precision_lie = eval_results.get('precision_lie', np.nan)\n    print(f\"\\nTest Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc:.4f}\\nTest Recall (Lie): {test_recall_lie:.4f}\\nTest Precision (Lie): {test_precision_lie:.4f}\")\n\n    print(\"Generating predictions for detailed metrics...\")\n    y_pred_probs = model.predict(test_dataset); y_pred_bin = (y_pred_probs > 0.5).astype(int).flatten(); y_true = labels_test\n\n    if len(y_true) != len(y_pred_bin):\n         print(f\"CRITICAL WARNING: Length mismatch true labels ({len(y_true)}) vs predictions ({len(y_pred_bin)}). Recalculating labels.\")\n         y_true_list_from_ds = [];\n         try:\n             for _, label_batch in test_dataset.as_numpy_iterator(): y_true_list_from_ds.extend(label_batch)\n             y_true = np.array(y_true_list_from_ds)\n             if len(y_true) > len(y_pred_bin): y_true = y_true[:len(y_pred_bin)]\n             elif len(y_true) < len(y_pred_bin): y_true= None\n         except tf.errors.OutOfRangeError: print(\"Could not recalculate labels. Metrics skipped.\"); y_true = None\n\n    if y_true is not None and len(y_true) == len(y_pred_bin):\n        f1_lie = f1_score(y_true, y_pred_bin, pos_label=0, zero_division=0); f1_truth = f1_score(y_true, y_pred_bin, pos_label=1, zero_division=0); f1_macro = f1_score(y_true, y_pred_bin, average='macro', zero_division=0); f1_weighted = f1_score(y_true, y_pred_bin, average='weighted', zero_division=0)\n        print(f\"\\nF1 Score (Lie=0): {f1_lie:.4f}\\nF1 Score (Truth=1): {f1_truth:.4f}\\nMacro F1 Score: {f1_macro:.4f}\\nWeighted F1 Score: {f1_weighted:.4f}\")\n        print(\"\\nClassification Report:\"); print(classification_report(y_true, y_pred_bin, target_names=['Lie (0)', 'Truth (1)'], digits=4, zero_division=0))\n\n        # 11. Plot Confusion Matrix\n        conf_matrix = confusion_matrix(y_true, y_pred_bin); plt.figure(figsize=(6, 5))\n        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred Lie(0)', 'Pred Truth(1)'], yticklabels=['Actual Lie(0)', 'Actual Truth(1)'])\n        plt.title(f'Baseline Hybrid (FastText, Tuned) CM\\nAcc:{test_acc:.3f}|MacroF1:{f1_macro:.3f}|Lie F1:{f1_lie:.3f}', fontsize=9); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.tight_layout()\n        plot_cm_path = os.path.join(OUTPUT_DIR, \"cm_baseline_hybrid_tuned_fasttext.png\");\n        try: plt.savefig(plot_cm_path); print(f\"Saved CM plot: {plot_cm_path}\")\n        except Exception as e: print(f\"Error saving CM plot: {e}\")\n        # plt.show()\n    else: print(\"Could not calculate detailed metrics due to label/prediction length issues.\")\n\n    print(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T12:06:17.651462Z","iopub.execute_input":"2025-04-15T12:06:17.651772Z","iopub.status.idle":"2025-04-15T12:12:52.696699Z","shell.execute_reply.started":"2025-04-15T12:06:17.651753Z","shell.execute_reply":"2025-04-15T12:12:52.695696Z"}},"outputs":[{"name":"stdout","text":"--- Loading Train/Val/Test Data ---\n\n--- Preprocessing ALL Data ---\n Preprocessed 17289 labeled messages. (Skipped 6 dialogues)\nCreating score lookup from 17289 samples...\nScore lookup created: 1389 entries (1389 unique). Skipped N/A: 0.\nAggregated samples into turns for 12 games.\nBuilding turn graph lookup (using A+I)...\nGraph lookup built: 312 turns processed.\n\n--- Tokenizing Text Data ---\nActual Vocab size used: 9946\n\n--- Preparing Train/Val/Test Data Splits ---\n Preprocessed 13132 labeled messages. (Skipped 5 dialogues)\n Preprocessed 1416 labeled messages. (Skipped 1 dialogues)\n Preprocessed 2741 labeled messages.\nPadded Shapes: Tr=(13132, 60), Vl=(1416, 60), Ts=(2741, 60)\n\n--- Downsampling Training Data ---\nOriginal Train counts: Lie(0)=591, Truth(1)=12541\nDownsampled Train counts: Lie(0)=591, Truth(1)=591\nDownsampled Shapes: Text=(1182, 60), Delta=(1182, 2), Labels=(1182,)\n\n--- Loading FastText Embeddings ---\nLoading FastText vectors from: /kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\nError: FastText file not found at /kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\nProceeding without pre-trained embeddings.\n\n--- Creating tf.data Datasets ---\nDatasets created.\n\n--- Building and Compiling Baseline Hybrid Model (FastText, Tuned) ---\nInitializing TextFeatureEncoder Embedding from scratch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"diplomacy_hybrid\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"diplomacy_hybrid\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mTextFeatureEncoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (\u001b[38;5;33mMultiHeadAttention\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (\u001b[38;5;33mAdd\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (\u001b[38;5;33mDropout\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (\u001b[38;5;33mDense\u001b[0m)    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (\u001b[38;5;33mDropout\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (\u001b[38;5;33mDense\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (\u001b[38;5;33mGraphEncoder\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ cast_mask_to_float_ge (\u001b[38;5;33mLambda\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ expand_mask_dim_ge (\u001b[38;5;33mReshape\u001b[0m)    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ mask_nodes_ge (\u001b[38;5;33mMultiply\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn1 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn2 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn3 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_pooled (\u001b[38;5;33mDropout\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (\u001b[38;5;33mDense\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (\u001b[38;5;33mConcatenate\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (\u001b[38;5;33mDense\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason1 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_12 (\u001b[38;5;33mReshape\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_13 (\u001b[38;5;33mReshape\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason2 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (\u001b[38;5;33mDense\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextFeatureEncoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphEncoder</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ cast_mask_to_float_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ expand_mask_dim_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ mask_nodes_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_pooled (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n--- Starting Training ---\nTraining Steps per Epoch: 37\nEpoch 1/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.5199 - loss: 0.6899 - precision_lie: 0.5020 - recall_lie: 0.5259\nEpoch 1: val_loss improved from inf to 0.55030, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 614ms/step - accuracy: 0.5206 - loss: 0.6897 - precision_lie: 0.5030 - recall_lie: 0.5289 - val_accuracy: 0.9032 - val_loss: 0.5503 - val_precision_lie: 0.9664 - val_recall_lie: 0.9316\nEpoch 2/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.5892 - loss: 0.6652 - precision_lie: 0.5659 - recall_lie: 0.7438\nEpoch 2: val_loss improved from 0.55030 to 0.52492, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 569ms/step - accuracy: 0.5895 - loss: 0.6652 - precision_lie: 0.5663 - recall_lie: 0.7432 - val_accuracy: 0.8806 - val_loss: 0.5249 - val_precision_lie: 0.9671 - val_recall_lie: 0.9066\nEpoch 3/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.6051 - loss: 0.6476 - precision_lie: 0.5865 - recall_lie: 0.6967\nEpoch 3: val_loss did not improve from 0.52492\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 570ms/step - accuracy: 0.6048 - loss: 0.6479 - precision_lie: 0.5863 - recall_lie: 0.6956 - val_accuracy: 0.8581 - val_loss: 0.5762 - val_precision_lie: 0.9677 - val_recall_lie: 0.8816\nEpoch 4/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.5816 - loss: 0.6708 - precision_lie: 0.5561 - recall_lie: 0.6298\nEpoch 4: val_loss did not improve from 0.52492\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 576ms/step - accuracy: 0.5821 - loss: 0.6704 - precision_lie: 0.5568 - recall_lie: 0.6316 - val_accuracy: 0.8588 - val_loss: 0.5839 - val_precision_lie: 0.9677 - val_recall_lie: 0.8824\nEpoch 5/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.6284 - loss: 0.6420 - precision_lie: 0.6084 - recall_lie: 0.7200\nEpoch 5: val_loss improved from 0.52492 to 0.47922, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 564ms/step - accuracy: 0.6282 - loss: 0.6420 - precision_lie: 0.6084 - recall_lie: 0.7190 - val_accuracy: 0.8891 - val_loss: 0.4792 - val_precision_lie: 0.9659 - val_recall_lie: 0.9169\nEpoch 6/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.6181 - loss: 0.6435 - precision_lie: 0.5913 - recall_lie: 0.6839\nEpoch 6: val_loss did not improve from 0.47922\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 578ms/step - accuracy: 0.6171 - loss: 0.6441 - precision_lie: 0.5909 - recall_lie: 0.6820 - val_accuracy: 0.8778 - val_loss: 0.6190 - val_precision_lie: 0.9662 - val_recall_lie: 0.9044\nEpoch 7/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.6101 - loss: 0.6512 - precision_lie: 0.5846 - recall_lie: 0.7140\nEpoch 7: val_loss improved from 0.47922 to 0.43729, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.6100 - loss: 0.6510 - precision_lie: 0.5848 - recall_lie: 0.7133 - val_accuracy: 0.9174 - val_loss: 0.4373 - val_precision_lie: 0.9655 - val_recall_lie: 0.9478\nEpoch 8/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.6210 - loss: 0.6484 - precision_lie: 0.5877 - recall_lie: 0.8198\nEpoch 8: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 563ms/step - accuracy: 0.6208 - loss: 0.6482 - precision_lie: 0.5877 - recall_lie: 0.8181 - val_accuracy: 0.8192 - val_loss: 0.6406 - val_precision_lie: 0.9710 - val_recall_lie: 0.8368\nEpoch 9/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.6551 - loss: 0.6196 - precision_lie: 0.6315 - recall_lie: 0.7142\nEpoch 9: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 573ms/step - accuracy: 0.6545 - loss: 0.6197 - precision_lie: 0.6310 - recall_lie: 0.7143 - val_accuracy: 0.8990 - val_loss: 0.4633 - val_precision_lie: 0.9656 - val_recall_lie: 0.9279\nEpoch 10/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.6675 - loss: 0.5963 - precision_lie: 0.6348 - recall_lie: 0.7514\nEpoch 10: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 576ms/step - accuracy: 0.6673 - loss: 0.5963 - precision_lie: 0.6351 - recall_lie: 0.7506 - val_accuracy: 0.9004 - val_loss: 0.4465 - val_precision_lie: 0.9642 - val_recall_lie: 0.9309\nEpoch 11/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.6797 - loss: 0.5772 - precision_lie: 0.6430 - recall_lie: 0.7905\nEpoch 11: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 565ms/step - accuracy: 0.6797 - loss: 0.5772 - precision_lie: 0.6432 - recall_lie: 0.7900 - val_accuracy: 0.8757 - val_loss: 0.4830 - val_precision_lie: 0.9654 - val_recall_lie: 0.9029\nEpoch 12/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.7301 - loss: 0.5226 - precision_lie: 0.7061 - recall_lie: 0.7798\nEpoch 12: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 585ms/step - accuracy: 0.7301 - loss: 0.5225 - precision_lie: 0.7059 - recall_lie: 0.7802 - val_accuracy: 0.7910 - val_loss: 0.6043 - val_precision_lie: 0.9667 - val_recall_lie: 0.8103\nEpoch 13/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.7691 - loss: 0.4810 - precision_lie: 0.7471 - recall_lie: 0.8312\nEpoch 13: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 573ms/step - accuracy: 0.7687 - loss: 0.4813 - precision_lie: 0.7464 - recall_lie: 0.8311 - val_accuracy: 0.7832 - val_loss: 0.6746 - val_precision_lie: 0.9655 - val_recall_lie: 0.8029\nEpoch 14/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.7872 - loss: 0.4406 - precision_lie: 0.7673 - recall_lie: 0.8330\nEpoch 14: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 565ms/step - accuracy: 0.7871 - loss: 0.4406 - precision_lie: 0.7669 - recall_lie: 0.8335 - val_accuracy: 0.7366 - val_loss: 0.7447 - val_precision_lie: 0.9643 - val_recall_lie: 0.7537\nEpoch 15/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.8029 - loss: 0.4037 - precision_lie: 0.7897 - recall_lie: 0.8221\nEpoch 15: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 576ms/step - accuracy: 0.8031 - loss: 0.4031 - precision_lie: 0.7896 - recall_lie: 0.8229 - val_accuracy: 0.6638 - val_loss: 0.9750 - val_precision_lie: 0.9672 - val_recall_lie: 0.6728\nEpoch 16/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.7636 - loss: 0.4898 - precision_lie: 0.7386 - recall_lie: 0.8208\nEpoch 16: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 557ms/step - accuracy: 0.7636 - loss: 0.4898 - precision_lie: 0.7386 - recall_lie: 0.8206 - val_accuracy: 0.5826 - val_loss: 1.0179 - val_precision_lie: 0.9695 - val_recall_lie: 0.5838\nEpoch 17/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.8535 - loss: 0.3417 - precision_lie: 0.8217 - recall_lie: 0.9279\nEpoch 17: val_loss did not improve from 0.43729\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 574ms/step - accuracy: 0.8541 - loss: 0.3405 - precision_lie: 0.8220 - recall_lie: 0.9281 - val_accuracy: 0.3609 - val_loss: 2.6274 - val_precision_lie: 0.9652 - val_recall_lie: 0.3471\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 7.\n\n--- Evaluating Model on Test Set ---\nLoading best model from: /kaggle/working/baseline_hybrid_tuned_fasttext.keras\nError loading model: <class '__main__.DiplomacyHybridModel'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': None, 'class_name': 'DiplomacyHybridModel', 'config': {'name': 'diplomacy_hybrid', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 132993401050768}, 'reason_dropout_rate': 0.4, 'attention_heads': 4}, 'registered_name': 'DiplomacyHybridModel', 'build_config': {'input_shape': [[60], [2], [7, 1], [7, 7], [7]]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'AdamW', 'config': {'name': 'adamw', 'learning_rate': 7.999999797903001e-05, 'weight_decay': 0.0001, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy', {'module': 'keras.metrics', 'class_name': 'Recall', 'config': {'name': 'recall_lie', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': 0}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Precision', 'config': {'name': 'precision_lie', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': 0}, 'registered_name': None}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: TextFeatureEncoder.from_config() got an unexpected keyword argument 'custom_objects'. Evaluating with final weights.\nEvaluating on test dataset...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.8930 - loss: 0.4357 - precision_lie: 0.9480 - recall_lie: 0.9372\n\nTest Loss: 0.4558\nTest Accuracy: 0.8712\nTest Recall (Lie): 0.9332\nTest Precision (Lie): 0.9262\nGenerating predictions for detailed metrics...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step\n\nF1 Score (Lie=0): 0.2343\nF1 Score (Truth=1): 0.9297\nMacro F1 Score: 0.5820\nWeighted F1 Score: 0.8688\n\nClassification Report:\n              precision    recall  f1-score   support\n\n     Lie (0)     0.2443    0.2250    0.2343       240\n   Truth (1)     0.9262    0.9332    0.9297      2501\n\n    accuracy                         0.8712      2741\n   macro avg     0.5853    0.5791    0.5820      2741\nweighted avg     0.8665    0.8712    0.8688      2741\n\nSaved CM plot: /kaggle/working/cm_baseline_hybrid_tuned_fasttext.png\n\n--- Script Finished ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# --- Imports ---\n# [Keep all existing imports]\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport re\nimport string\nimport glob\nimport warnings\nimport random\nimport time\nimport requests # Added\nimport zipfile # Added (though FastText .vec isn't zipped usually)\nimport gzip # Added for potential .gz files\nimport shutil # Added for unzipping .gz\n\n# Scikit-learn imports\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.utils import resample\n\n# TensorFlow / Keras imports\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, Embedding, Dense, Dropout, Concatenate,\n                                     Layer, MultiHeadAttention, LayerNormalization,\n                                     GlobalAveragePooling1D, Add, Reshape,\n                                     Multiply, Lambda)\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# --- Constants and Configuration ---\n# [Keep all existing constants]\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Data/Model Paths\nBASE_DATA_DIR = './Dataset/'\nKAGGLE_DATA_DIR = '/kaggle/input/diplomacy/transformers/default/1/Dataset/'\nif os.path.exists(KAGGLE_DATA_DIR): BASE_DATA_DIR = KAGGLE_DATA_DIR\nDATA_DIR = os.path.join(BASE_DATA_DIR, 'data')\nOUTPUT_DIR = '/kaggle/working/' if os.path.exists('/kaggle/working/') else './output/'\n# *** Define FastText URL and expected file name ***\n# crawl-300d-2M.vec.zip is a common way it's distributed, but the .vec file itself isn't always zipped.\n# Check the source you intend to use. Using the .gz version URL as an example.\nFASTTEXT_URL = 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip' # Check if this is zipped or .gz\nFASTTEXT_ZIP_FILE = os.path.join(OUTPUT_DIR, 'crawl-300d-2M.vec.zip') # Or .gz\nFASTTEXT_FILE = os.path.join(OUTPUT_DIR, 'crawl-300d-2M.vec') # The final uncompressed file\n# FASTTEXT_PATH should point to the final UNCOMPRESSED file location\nFASTTEXT_PATH = FASTTEXT_FILE # Use the constant defined above\n\nos.makedirs(OUTPUT_DIR, exist_ok=True) # Create output dir if needed\n\n# Model Hyperparameters\nMAX_SEQUENCE_LENGTH = 60; MAX_VOCAB_SIZE = 10000; EMBEDDING_DIM = 300\nNODE_FEATURE_DIM = 1; DELTA_FEATURE_DIM = 2; MAX_PLAYERS = 7\nNUM_HEADS_TXT=4; NUM_HEADS_REASON=4; GCN_UNITS=64\nDROPOUT_RATE_ENCODER = 0.15; DROPOUT_RATE_FUSION = 0.4\nLEARNING_RATE = 8e-5; WEIGHT_DECAY = 1e-4\nBATCH_SIZE = 32; EPOCHS = 50; PATIENCE = 10\n\n# --- Helper Functions ---\n# [Keep load_jsonl_dataset, clean_text, preprocess_for_hybrid, create_score_lookup,\n#  get_next_turn, extract_delta_features, aggregate_data_by_turn, build_turn_graph_lookup]\n# (Definitions are identical)\ndef load_jsonl_dataset(file_path):\n    data = []\n    skipped_lines = 0\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f):\n                try: data.append(json.loads(line))\n                except json.JSONDecodeError: skipped_lines += 1\n    except FileNotFoundError: print(f\"Error: File not found at {file_path}\"); return None\n    if skipped_lines > 0: print(f\"Warn: Skipped {skipped_lines} invalid JSON lines in {file_path}\")\n    return data\n\ndef clean_text(text):\n    if not isinstance(text, str): return \"\"\n    text = text.lower(); text = re.sub(r'http\\S+|@\\w+|#\\w+', '', text)\n    text = text.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\")))\n    text = re.sub(r'\\d+', '', text); text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef preprocess_for_hybrid(data_raw):\n    processed_samples = []; skipped_dialogues=0\n    if data_raw is None: return processed_samples\n    for dialogue_idx, dialogue_sample in enumerate(data_raw):\n        game_id=dialogue_sample.get('game_id'); messages=dialogue_sample.get('messages',[]); speakers=dialogue_sample.get('speakers',[]); recipients=dialogue_sample.get('receivers',[])\n        years=dialogue_sample.get('years',[]); seasons=dialogue_sample.get('seasons',[]); sender_labels=dialogue_sample.get('sender_labels',[]); game_scores=dialogue_sample.get('game_score',[]); game_score_deltas=dialogue_sample.get('game_score_delta',[])\n        list_len=len(messages)\n        required_lists = [speakers, recipients, years, seasons, sender_labels, game_scores, game_score_deltas]\n        if not (game_id and list_len > 0 and sender_labels is not None and all(isinstance(lst, list) and len(lst) == list_len for lst in required_lists if lst is not None)):\n             skipped_dialogues+=1; continue\n        for i in range(list_len):\n            label=-1; score_num=np.nan; delta_num=np.nan\n            if isinstance(sender_labels, list) and i < len(sender_labels):\n                if sender_labels[i] is False: label=0\n                elif sender_labels[i] is True: label=1\n            else: continue\n            try:\n                if game_scores and i < len(game_scores) and game_scores[i] is not None: score_num=float(game_scores[i])\n            except (ValueError, TypeError): pass\n            try:\n                if game_score_deltas and i < len(game_score_deltas) and game_score_deltas[i] is not None: delta_num=float(game_score_deltas[i])\n            except (ValueError, TypeError): pass\n            if label != -1:\n                processed_delta = delta_num if pd.notna(delta_num) else 0.0\n                processed_samples.append({'text': messages[i] if messages and i < len(messages) else \"\", 'clean_text': clean_text(messages[i] if messages and i < len(messages) else \"\"), 'label': label, 'game_id': game_id, 'year': str(years[i] if years and i < len(years) else 'unknown'), 'season': str(seasons[i] if seasons and i < len(seasons) else 'unknown').lower(), 'speaker': str(speakers[i] if speakers and i < len(speakers) else 'unknown').lower(), 'recipient': str(recipients[i] if recipients and i < len(recipients) else 'unknown').lower(), 'score_numeric': score_num, 'delta_numeric': processed_delta})\n    print(f\" Preprocessed {len(processed_samples)} labeled messages.\", end=\"\")\n    if skipped_dialogues > 0: print(f\" (Skipped {skipped_dialogues} dialogues)\", end=\"\")\n    print()\n    return processed_samples\n\ndef create_score_lookup(all_samples):\n    score_lookup=defaultdict(lambda:np.nan); processed_keys=set(); valid_scores=0; skipped_no_score=0\n    print(f\"Creating score lookup from {len(all_samples)} samples...\")\n    for sample in all_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); player=sample.get('speaker'); score_num=sample.get('score_numeric')\n        if game_id is not None and year!='unknown' and season!='unknown' and player!='unknown':\n            key=(game_id,year,season,player)\n            if key not in processed_keys:\n                if pd.notna(score_num): score_lookup[key]=score_num; valid_scores+=1\n                else: skipped_no_score+=1\n                processed_keys.add(key)\n    print(f\"Score lookup created: {len(score_lookup)} entries ({valid_scores} unique). Skipped N/A: {skipped_no_score}.\")\n    return score_lookup\n\ndef get_next_turn(current_year_str, current_season_str):\n    try:\n        current_year = int(current_year_str); current_season = str(current_season_str).lower()\n        if current_season == 'spring': return str(current_year), 'fall'\n        elif current_season == 'fall': return str(current_year), 'winter'\n        elif current_season == 'winter': return str(current_year + 1), 'spring'\n        else: return None, None\n    except (ValueError, TypeError): return None, None\n\ndef extract_delta_features(sample_info, score_lookup):\n    current_delta = sample_info.get('delta_numeric', 0.0); future_delta = 0.0\n    game_id=sample_info.get('game_id'); year=sample_info.get('year'); season=sample_info.get('season'); speaker=sample_info.get('speaker'); recipient=sample_info.get('recipient')\n    if game_id is not None and year!='unknown' and season!='unknown' and speaker!='unknown' and recipient!='unknown':\n        next_year, next_season = get_next_turn(year, season)\n        if next_year and next_season:\n            fut_spk_score = score_lookup.get((game_id, next_year, next_season, speaker), np.nan); fut_rec_score = score_lookup.get((game_id, next_year, next_season, recipient), np.nan)\n            if pd.notna(fut_spk_score) and pd.notna(fut_rec_score):\n                try: future_delta = float(fut_spk_score) - float(fut_rec_score)\n                except (ValueError, TypeError): future_delta = 0.0\n    return np.array([current_delta, future_delta], dtype=np.float32)\n\ndef aggregate_data_by_turn(all_processed_samples):\n    games_data = defaultdict(lambda: defaultdict(lambda: {'messages': [], 'players': set()}))\n    for sample in all_processed_samples:\n        game_id=sample.get('game_id'); year=sample.get('year'); season=sample.get('season'); speaker=sample.get('speaker'); recipient=sample.get('recipient')\n        if game_id is None or year=='unknown' or season=='unknown': continue\n        turn_key=(year,season); player_set = set()\n        if speaker is not None and speaker != 'unknown': player_set.add(speaker)\n        if recipient is not None and recipient != 'unknown': player_set.add(recipient)\n        if player_set: games_data[game_id][turn_key]['players'].update(player_set); games_data[game_id][turn_key]['messages'].append({'speaker':speaker,'recipient':recipient})\n    print(f\"Aggregated samples into turns for {len(games_data)} games.\")\n    return games_data\n\ndef build_turn_graph_lookup(games_data_agg, score_lookup):\n    print(\"Building turn graph lookup (using A+I)...\"); graph_lookup={}; player_maps_game={}\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); default_A = np.identity(MAX_PLAYERS, dtype=np.float32); default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}; skipped_games_players = 0; processed_turns = 0\n    for game_id, turns in games_data_agg.items():\n        all_p_in_game = set();\n        for turn_data in turns.values(): valid_players_in_turn = {p for p in turn_data['players'] if p is not None and p != 'unknown'}; all_p_in_game.update(valid_players_in_turn)\n        if not all_p_in_game: skipped_games_players += 1; continue\n        sorted_p = sorted(list(all_p_in_game)); num_p_game = len(sorted_p)\n        if num_p_game > MAX_PLAYERS: sorted_p = sorted_p[:MAX_PLAYERS]; num_p_game = MAX_PLAYERS\n        p2i = {p: i for i, p in enumerate(sorted_p)}; player_maps_game[game_id] = p2i\n        for (yr, sn), t_data in turns.items():\n            tk = (game_id, yr, sn); X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); M = np.zeros(MAX_PLAYERS, dtype=bool); Ab = np.zeros((MAX_PLAYERS, MAX_PLAYERS), dtype=np.float32)\n            current_turn_players = {p for p in t_data['players'] if p is not None and p != 'unknown'}\n            for p in current_turn_players:\n                idx = p2i.get(p)\n                if idx is not None: score = score_lookup.get((game_id, yr, sn, p), np.nan); X[idx, 0] = 0.0 if pd.isna(score) else float(score); M[idx] = True\n            for msg in t_data['messages']: i_s = p2i.get(msg.get('speaker')); i_r = p2i.get(msg.get('recipient'));\n            if i_s is not None and i_r is not None and i_s != i_r: Ab[i_s, i_r] = 1.0; Ab[i_r, i_s] = 1.0\n            Asl = Ab + np.identity(MAX_PLAYERS, dtype=np.float32); graph_lookup[tk] = {'X': X, 'A': Asl, 'M': M}; processed_turns += 1\n    print(f\"Graph lookup built: {processed_turns} turns processed.\")\n    if skipped_games_players > 0: print(f\"Skipped {skipped_games_players} games.\")\n    return graph_lookup, player_maps_game\n\n# --- GCN Layer Definition ---\nclass GCNLayer(layers.Layer):\n    def __init__(self, units, activation=None, name=None, **kwargs): super().__init__(name=name, **kwargs); self.units = units; self.activation = tf.keras.activations.get(activation)\n    def build(self, input_shape): node_feature_shape = tf.TensorShape(input_shape[0]); node_dim = int(node_feature_shape[-1]); self.w = self.add_weight(shape=(node_dim, self.units), initializer='glorot_uniform', name='w', trainable=True); self.b = self.add_weight(shape=(self.units,), initializer='zeros', name='b', trainable=True); super().build(input_shape)\n    def call(self, inputs):\n        node_features, adj_matrix = inputs\n        support = tf.matmul(node_features, self.w)\n        output = tf.matmul(adj_matrix, support)\n        output = output + self.b\n        if self.activation is not None:\n            output = self.activation(output)\n        # Corrected Indentation: return is now outside the if block\n        return output\n    def compute_output_shape(self, input_shape): node_feature_shape = tf.TensorShape(input_shape[0]); batch_size = node_feature_shape[0]; num_nodes = node_feature_shape[1]; return tf.TensorShape((batch_size, num_nodes, self.units))\n    def get_config(self): config = super().get_config(); config.update({\"units\": self.units, \"activation\": tf.keras.activations.serialize(self.activation)}); return config\n    @classmethod\n    def from_config(cls, config): activation_config = config.pop(\"activation\", None); activation = tf.keras.activations.deserialize(activation_config) if activation_config else None; config['activation'] = activation; return cls(**config)\n\n# --- Baseline Model Classes ---\nclass TextFeatureEncoder(Model):\n    def __init__(self, max_vocab_size, embedding_dim, seq_len, num_heads, dropout_rate, delta_feature_dim, embedding_matrix=None, name=\"text_feature_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.seq_len = seq_len; self.delta_feature_dim = delta_feature_dim;\n        if embedding_matrix is not None: print(\"Initializing TextFeatureEncoder Embedding with pre-trained weights.\"); self.embedding=layers.Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=seq_len, weights=[embedding_matrix], trainable=True, name='embedding')\n        else: print(\"Initializing TextFeatureEncoder Embedding from scratch.\"); self.embedding=layers.Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=seq_len, trainable=True, name='embedding')\n        self.mha=layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, name='attention'); self.add_norm1=layers.Add(name='add_resid_1'); self.layernorm1=layers.LayerNormalization(epsilon=1e-6, name='norm_1'); self.pooling=layers.GlobalAveragePooling1D(name='text_pooling'); self.dropout_text1=layers.Dropout(dropout_rate, name='text_dropout_1'); self.dense_features=layers.Dense(16, activation='relu', name='dense_delta_features'); self.concatenate=layers.Concatenate(name='concat_text_features'); self.dropout_combined=layers.Dropout(dropout_rate*1.5, name='text_feature_dropout'); self.output_dim = embedding_dim; self.output_dense=layers.Dense(self.output_dim, activation='relu', name='text_feature_output')\n    def call(self, inputs, training=False): text_input, feature_input = inputs; x_txt = self.embedding(text_input); attn_output = self.mha(query=x_txt, value=x_txt, key=x_txt, training=training); x_txt = self.add_norm1([x_txt, attn_output]); x_txt = self.layernorm1(x_txt); text_emb = self.pooling(x_txt); text_emb = self.dropout_text1(text_emb, training=training); feature_proc = self.dense_features(feature_input); combined = self.concatenate([text_emb, feature_proc]); combined_dropout = self.dropout_combined(combined, training=training); output_embedding = self.output_dense(combined_dropout); return output_embedding\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, self.output_dim))\n    def get_config(self): config=super().get_config(); config.update({'max_vocab_size':self.embedding.input_dim, 'embedding_dim':self.embedding.output_dim, 'seq_len': self.seq_len, 'num_heads':self.mha.num_heads,'dropout_rate':self.dropout_text1.rate, 'delta_feature_dim': self.delta_feature_dim}); config.pop('embedding_matrix', None); return config\n    @classmethod\n    def from_config(cls, config): return cls(**config)\n\nclass GraphEncoder(Model):\n    def __init__(self, max_players, node_feature_dim, gcn_units, dropout_rate, final_emb_dim, name=\"graph_encoder\", **kwargs):\n        super().__init__(name=name, **kwargs); self.max_players=max_players; self.final_emb_dim=final_emb_dim; self.node_feature_dim=node_feature_dim; self.gcn_units = gcn_units;\n        self.cast_mask = layers.Lambda(lambda x: tf.cast(x, dtype=tf.float32), name='cast_mask_to_float_ge'); self.expand_mask = layers.Reshape((max_players, 1), name='expand_mask_dim_ge'); self.mask_mult = layers.Multiply(name='mask_nodes_ge'); self.gcn1=GCNLayer(gcn_units, activation='relu', name='CustomGCN1'); self.dropout_gcn1=layers.Dropout(dropout_rate, name='dropout_gcn1'); self.gcn2=GCNLayer(gcn_units, activation='relu', name='CustomGCN2'); self.dropout_gcn2=layers.Dropout(dropout_rate, name='dropout_gcn2'); self.gcn3=GCNLayer(gcn_units // 2, activation='relu', name='CustomGCN3'); self.dropout_gcn3=layers.Dropout(dropout_rate, name='dropout_gcn3'); self.graph_pooling=layers.GlobalAveragePooling1D(name='GraphPooling'); self.dropout_pooled=layers.Dropout(dropout_rate * 1.5, name='dropout_pooled'); self.output_dense=layers.Dense(self.final_emb_dim, activation='relu', name='graph_output')\n    def call(self, inputs, training=False): node_features, adj_matrix, node_mask = inputs; node_mask_float=self.cast_mask(node_mask); node_mask_expanded=self.expand_mask(node_mask_float); masked_node_features=self.mask_mult([node_features, node_mask_expanded]); x_graph = self.gcn1([masked_node_features, adj_matrix]); x_graph = self.dropout_gcn1(x_graph, training=training); x_graph = self.gcn2([x_graph, adj_matrix]); x_graph = self.dropout_gcn2(x_graph, training=training); x_graph = self.gcn3([x_graph, adj_matrix]); x_graph = self.dropout_gcn3(x_graph, training=training); graph_emb_pooled = self.graph_pooling(x_graph, mask=node_mask); graph_emb_pooled = self.dropout_pooled(graph_emb_pooled, training=training); graph_embedding = self.output_dense(graph_emb_pooled); return graph_embedding\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, self.final_emb_dim))\n    def get_config(self): config = super().get_config(); config.update({'max_players':self.max_players, 'node_feature_dim':self.node_feature_dim, 'gcn_units':self.gcn_units, 'dropout_rate':self.dropout_gcn1.rate, 'final_emb_dim':self.final_emb_dim}); return config\n    @classmethod\n    def from_config(cls, config, custom_objects=None): return cls(**config)\n\nclass DiplomacyHybridModel(Model):\n    def __init__(self, text_feature_encoder, graph_encoder, reason_dropout_rate, attention_heads, name=\"diplomacy_hybrid\", **kwargs):\n        super().__init__(name=name, **kwargs); self.text_feature_encoder = text_feature_encoder; self.graph_encoder = graph_encoder; self.concatenate = layers.Concatenate(name='combine_embeddings')\n        try: text_out_dim = text_feature_encoder.output_dim; graph_out_dim = graph_encoder.final_emb_dim\n        except AttributeError: text_out_dim = EMBEDDING_DIM; graph_out_dim = EMBEDDING_DIM // 2\n        combined_dim = text_out_dim + graph_out_dim\n        self.reason_dropout_rate = reason_dropout_rate; self.attention_heads = attention_heads;\n        self.reason_dense1 = layers.Dense(combined_dim, activation='relu', name='reason_dense1'); self.dropout_reason1 = layers.Dropout(self.reason_dropout_rate, name='dropout_reason1'); self.reshape_for_attn = layers.Reshape((1, combined_dim)); attn_key_dim = max(16, combined_dim // self.attention_heads); self.attention_reason = layers.MultiHeadAttention(num_heads=self.attention_heads, key_dim=attn_key_dim, name='reason_attention'); self.reshape_after_attn = layers.Reshape((combined_dim,)); self.dropout_reason2 = layers.Dropout(self.reason_dropout_rate, name='dropout_reason2'); self.output_classifier = layers.Dense(1, activation='sigmoid', name='final_output')\n    def call(self, inputs, training=False): text_input, feature_input, node_features, adj_matrix, node_mask = inputs; text_feat_emb = self.text_feature_encoder([text_input, feature_input], training=training); graph_emb = self.graph_encoder([node_features, adj_matrix, node_mask], training=training); combined = self.concatenate([text_feat_emb, graph_emb]); x = self.reason_dense1(combined); x = self.dropout_reason1(x, training=training); x_reshaped = self.reshape_for_attn(x); attn_output = self.attention_reason(query=x_reshaped, value=x_reshaped, key=x_reshaped, training=training); x = self.reshape_after_attn(attn_output); x = self.dropout_reason2(x, training=training); output = self.output_classifier(x); return output\n    def compute_output_shape(self, input_shape): batch_size = input_shape[0][0]; return tf.TensorShape((batch_size, 1))\n    def get_config(self): config = super().get_config(); config.update({\"text_feature_encoder_config\": self.text_feature_encoder.get_config(), \"graph_encoder_config\": self.graph_encoder.get_config(), \"reason_dropout_rate\": self.reason_dropout_rate, \"attention_heads\": self.attention_heads}); config.pop(\"text_feature_encoder\", None); config.pop(\"graph_encoder\", None); return config\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        text_encoder_config = config.pop(\"text_feature_encoder_config\"); graph_encoder_config = config.pop(\"graph_encoder_config\")\n        text_encoder = TextFeatureEncoder.from_config(text_encoder_config, custom_objects=custom_objects)\n        graph_encoder = GraphEncoder.from_config(graph_encoder_config, custom_objects=custom_objects)\n        return cls(text_feature_encoder=text_encoder, graph_encoder=graph_encoder, **config)\n\n\n# --- FastText Loading/Downloading Functions ---\ndef download_fasttext_if_not_present(zip_path=FASTTEXT_ZIP_FILE, extract_path=OUTPUT_DIR, final_file=FASTTEXT_FILE):\n    \"\"\"Downloads and extracts FastText embeddings if not found.\"\"\"\n    if not os.path.exists(final_file):\n        print(f\"FastText file not found at {final_file}.\")\n        if not os.path.exists(zip_path):\n            print(f\"Downloading FastText embeddings from {FASTTEXT_URL}...\")\n            try:\n                with requests.get(FASTTEXT_URL, stream=True) as r:\n                    r.raise_for_status()\n                    with open(zip_path, 'wb') as f:\n                        for chunk in r.iter_content(chunk_size=8192*1024): # Larger chunk size for big files\n                            f.write(chunk)\n                print(\"Download complete.\")\n            except requests.exceptions.RequestException as e:\n                print(f\"Error downloading FastText: {e}\")\n                return False\n            except Exception as e:\n                 print(f\"An unexpected error occurred during download: {e}\")\n                 return False\n        else:\n            print(f\"Compressed file found at {zip_path}, proceeding with extraction.\")\n\n        print(f\"Extracting FastText embeddings to {extract_path}...\")\n        try:\n            # Check if it's a zip or gz file based on extension\n            if zip_path.endswith('.zip'):\n                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                    zip_ref.extractall(extract_path)\n            elif zip_path.endswith('.gz'):\n                 with gzip.open(zip_path, 'rb') as f_in:\n                    with open(final_file, 'wb') as f_out:\n                         shutil.copyfileobj(f_in, f_out)\n            else:\n                print(f\"Error: Unknown compression format for {zip_path}\")\n                return False # Unknown format\n            print(\"Extraction complete.\")\n            # Optionally remove the compressed file\n            # print(f\"Removing compressed file: {zip_path}\")\n            # os.remove(zip_path)\n        except (zipfile.BadZipFile, gzip.BadGzipFile):\n            print(f\"Error: Downloaded file '{zip_path}' is not a valid archive. Please delete it and retry.\")\n            if os.path.exists(zip_path): os.remove(zip_path)\n            return False\n        except Exception as e:\n            print(f\"Error extracting FastText: {e}\")\n            return False\n\n        # Verify extraction\n        if not os.path.exists(final_file):\n            print(f\"Error: Expected FastText file '{final_file}' not found after extraction.\")\n            return False\n    else:\n        print(f\"FastText file found at {final_file}.\")\n    return True\n\ndef load_fasttext_embedding_matrix(filepath, word_index, embedding_dim, max_vocab_size):\n    # [Keep the FastText loading function as before]\n    print(f\"Loading FastText vectors from: {filepath}\")\n    if not os.path.exists(filepath): print(f\"Error: FastText file not found at {filepath}\"); return None\n    start_time = time.time(); embeddings_index = {}; skipped_lines = 0; skipped_dims = 0\n    try:\n        with open(filepath, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n            for i, line in enumerate(f):\n                if i == 0 and len(line.split()) == 2:\n                    try: int(line.split()[0]); continue\n                    except ValueError: pass\n                values = line.split(); word = values[0]\n                try:\n                    coefs = np.asarray(values[1:], dtype='float32')\n                    if len(coefs) == embedding_dim: embeddings_index[word] = coefs\n                    else: skipped_dims += 1\n                except ValueError: skipped_lines += 1; continue\n    except Exception as e: print(f\"An error occurred: {e}\"); return None\n    load_time = time.time() - start_time; print(f\"Found {len(embeddings_index)} vectors in {load_time:.2f}s.\")\n    if skipped_lines > 0: print(f\"  Skipped {skipped_lines} lines (parsing).\")\n    if skipped_dims > 0: print(f\"  Skipped {skipped_dims} words (dimension mismatch).\")\n    num_tokens = min(max_vocab_size, len(word_index) + 1); hits = 0; misses = 0\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n    for word, i in word_index.items():\n        if i >= num_tokens: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector; hits += 1\n        else: misses += 1\n    print(f\"Prepared embedding matrix: Shape {embedding_matrix.shape}\"); print(f\"  Converted {hits} words ({misses} misses).\")\n    return embedding_matrix\n\n# --- Data Generator Function ---\n# [Keep the Data Generator function as before]\ndef data_generator_split(text_padded_arr, delta_feats_arr, labels_arr, turn_keys_list, graph_lookup):\n    num_samples = len(labels_arr); indices = np.arange(num_samples)\n    default_X = np.zeros((MAX_PLAYERS, NODE_FEATURE_DIM), dtype=np.float32); default_A = np.identity(MAX_PLAYERS, dtype=np.float32); default_M = np.zeros(MAX_PLAYERS, dtype=bool)\n    default_graph = {'X': default_X, 'A': default_A, 'M': default_M}\n    for i in indices:\n        text_pad = text_padded_arr[i]; delta_f = delta_feats_arr[i]; label = labels_arr[i]; turn_key = turn_keys_list[i]\n        graph_data = graph_lookup.get(turn_key, default_graph)\n        X_g = graph_data.get('X', default_graph['X']); A_g = graph_data.get('A', default_graph['A']); M_g = graph_data.get('M', default_graph['M'])\n        if X_g.shape != (MAX_PLAYERS, NODE_FEATURE_DIM) or A_g.shape != (MAX_PLAYERS, MAX_PLAYERS) or M_g.shape != (MAX_PLAYERS,):\n            X_g, A_g, M_g = default_graph['X'], default_graph['A'], default_graph['M']\n        yield (text_pad, delta_f, X_g, A_g, M_g), label\n\n\n# --- Main Training Script ---\nif __name__ == \"__main__\":\n    # 1. Load Data\n    # [Keep Load Data section]\n    print(\"--- Loading Train/Val/Test Data ---\")\n    train_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'train.jsonl')); val_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'validation.jsonl')); test_raw = load_jsonl_dataset(os.path.join(DATA_DIR, 'test.jsonl'))\n    if train_raw is None or val_raw is None or test_raw is None: raise ValueError(\"Failed data loading.\")\n    all_raw_data = train_raw + val_raw + test_raw\n\n    # 2. Preprocess ALL Data\n    # [Keep Preprocess ALL Data section]\n    print(\"\\n--- Preprocessing ALL Data ---\")\n    all_processed = preprocess_for_hybrid(all_raw_data);\n    if not all_processed: raise ValueError(\"Preprocessing failed.\")\n    score_lookup = create_score_lookup(all_processed)\n    games_data_agg = aggregate_data_by_turn(all_processed)\n    graph_lookup, player_maps_game = build_turn_graph_lookup(games_data_agg, score_lookup)\n\n    # 3. Fit Tokenizer\n    # [Keep Fit Tokenizer section]\n    print(\"\\n--- Tokenizing Text Data ---\")\n    all_texts = [s['clean_text'] for s in all_processed]\n    tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n    tokenizer.fit_on_texts(all_texts); word_index = tokenizer.word_index\n    vocab_size = min(MAX_VOCAB_SIZE, len(word_index) + 1)\n    print(f\"Actual Vocab size used: {vocab_size}\")\n\n    # 4. Prepare SEPARATE Data Splits\n    # [Keep Prepare SEPARATE Data Splits section]\n    print(\"\\n--- Preparing Train/Val/Test Data Splits ---\")\n    train_processed = preprocess_for_hybrid(train_raw); val_processed = preprocess_for_hybrid(val_raw); test_processed = preprocess_for_hybrid(test_raw)\n    if not train_processed or not val_processed or not test_processed: raise ValueError(\"Data splits empty.\")\n    def tokenize_and_pad(samples): texts=[s['clean_text'] for s in samples]; sequences=tokenizer.texts_to_sequences(texts); return pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post',truncating='post')\n    padded_train=tokenize_and_pad(train_processed); padded_val=tokenize_and_pad(val_processed); padded_test=tokenize_and_pad(test_processed)\n    print(f\"Padded Shapes: Tr={padded_train.shape}, Vl={padded_val.shape}, Ts={padded_test.shape}\")\n    def extract_features_labels_keys(samples): labels=np.array([s['label'] for s in samples]); delta_feats=np.array([extract_delta_features(s, score_lookup) for s in samples]); turn_keys=[(s['game_id'],s['year'],s['season']) for s in samples]; return labels, delta_feats, turn_keys\n    labels_train, delta_feats_train, turn_keys_train = extract_features_labels_keys(train_processed); labels_val, delta_feats_val, turn_keys_val = extract_features_labels_keys(val_processed); labels_test, delta_feats_test, turn_keys_test = extract_features_labels_keys(test_processed)\n\n\n    # 5. Apply Downsampling\n    # [Keep Downsampling section]\n    print(\"\\n--- Downsampling Training Data ---\")\n    train_indices = np.arange(len(labels_train)); minority_indices = train_indices[labels_train == 0]; majority_indices = train_indices[labels_train == 1]\n    print(f\"Original Train counts: Lie(0)={len(minority_indices)}, Truth(1)={len(majority_indices)}\")\n    if len(minority_indices) == 0 or len(majority_indices) == 0: raise ValueError(\"Cannot downsample.\")\n    majority_downsampled_indices = resample(majority_indices, replace=False, n_samples=len(minority_indices), random_state=SEED)\n    downsampled_train_indices = np.concatenate([minority_indices, majority_downsampled_indices]); np.random.shuffle(downsampled_train_indices)\n    padded_train_ds = padded_train[downsampled_train_indices]; delta_feats_train_ds = delta_feats_train[downsampled_train_indices]; labels_train_ds = labels_train[downsampled_train_indices]; turn_keys_train_list_ds = [turn_keys_train[i] for i in downsampled_train_indices]\n    print(f\"Downsampled Train counts: Lie(0)={sum(labels_train_ds==0)}, Truth(1)={sum(labels_train_ds==1)}\")\n    print(f\"Downsampled Shapes: Text={padded_train_ds.shape}, Delta={delta_feats_train_ds.shape}, Labels={labels_train_ds.shape}\")\n\n    # 6. Download and Load FastText Embedding Matrix\n    print(\"\\n--- Loading FastText Embeddings (Downloading if needed) ---\")\n    # Use the specific FastText file path defined in constants\n    if download_fasttext_if_not_present(zip_path=FASTTEXT_ZIP_FILE, final_file=FASTTEXT_FILE):\n        embedding_matrix = load_fasttext_embedding_matrix(FASTTEXT_FILE, word_index, EMBEDDING_DIM, vocab_size)\n    else:\n        print(\"Failed to download/extract FastText. Proceeding without pre-trained embeddings.\")\n        embedding_matrix = None\n\n    # 7. Create tf.data Datasets\n    # [Keep Create Datasets section]\n    print(\"\\n--- Creating tf.data Datasets ---\")\n    output_signature = ((tf.TensorSpec(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32), tf.TensorSpec(shape=(DELTA_FEATURE_DIM,), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, NODE_FEATURE_DIM), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS, MAX_PLAYERS), dtype=tf.float32), tf.TensorSpec(shape=(MAX_PLAYERS,), dtype=tf.bool)), tf.TensorSpec(shape=(), dtype=tf.int32))\n    train_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_train_ds, delta_feats_train_ds, labels_train_ds, turn_keys_train_list_ds, graph_lookup), output_signature=output_signature).shuffle(buffer_size=len(labels_train_ds)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).repeat()\n    val_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_val, delta_feats_val, labels_val, turn_keys_val, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    test_dataset = tf.data.Dataset.from_generator(lambda: data_generator_split(padded_test, delta_feats_test, labels_test, turn_keys_test, graph_lookup), output_signature=output_signature).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    print(\"Datasets created.\")\n\n\n    # 8. Build & Compile Model\n    # [Keep Build & Compile section as before - should now work]\n    print(\"\\n--- Building and Compiling Baseline Hybrid Model (FastText, Tuned) ---\")\n    final_graph_emb_dim = EMBEDDING_DIM // 2\n    text_encoder = TextFeatureEncoder(max_vocab_size=vocab_size, embedding_dim=EMBEDDING_DIM, seq_len=MAX_SEQUENCE_LENGTH, num_heads=NUM_HEADS_TXT, dropout_rate=DROPOUT_RATE_ENCODER, delta_feature_dim=DELTA_FEATURE_DIM, embedding_matrix=embedding_matrix)\n    graph_encoder = GraphEncoder(max_players=MAX_PLAYERS, node_feature_dim=NODE_FEATURE_DIM, gcn_units=GCN_UNITS, dropout_rate=DROPOUT_RATE_ENCODER, final_emb_dim=final_graph_emb_dim)\n    diplomacy_model = DiplomacyHybridModel(text_feature_encoder=text_encoder, graph_encoder=graph_encoder, reason_dropout_rate=DROPOUT_RATE_FUSION, attention_heads=NUM_HEADS_REASON)\n    optimizer = AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    diplomacy_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(class_id=0, name='recall_lie'), tf.keras.metrics.Precision(class_id=0, name='precision_lie')])\n    input_shapes_only = [spec.shape for spec in output_signature[0]]\n    diplomacy_model.build(input_shape=input_shapes_only)\n    diplomacy_model.summary(expand_nested=True)\n\n    # 9. Train Model\n    # [Keep Training loop as before]\n    print(\"\\n--- Starting Training ---\")\n    model_filename = \"baseline_hybrid_tuned_fasttext.keras\"; model_path = os.path.join(OUTPUT_DIR, model_filename)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1, restore_best_weights=True, mode='min')\n    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1, save_weights_only=False)\n    steps_per_epoch_train = len(labels_train_ds) // BATCH_SIZE + (1 if len(labels_train_ds) % BATCH_SIZE != 0 else 0)\n    print(f\"Training Steps per Epoch: {steps_per_epoch_train}\")\n    history = diplomacy_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, steps_per_epoch=steps_per_epoch_train, callbacks=[early_stopping, checkpoint], verbose=1)\n\n\n    # 10. Evaluate Model\n    # [Keep Evaluation section as before]\n    print(\"\\n--- Evaluating Model on Test Set ---\")\n    if os.path.exists(model_path):\n        print(f\"Loading best model from: {model_path}\")\n        try:\n            custom_objects = {'TextFeatureEncoder': TextFeatureEncoder, 'GraphEncoder': GraphEncoder, 'GCNLayer': GCNLayer, 'DiplomacyHybridModel': DiplomacyHybridModel}\n            model = tf.keras.models.load_model(model_path, custom_objects=custom_objects); print(\"Model loaded successfully.\")\n        except Exception as e: print(f\"Error loading model: {e}. Evaluating with final weights.\"); model = diplomacy_model\n    else: print(\"Warning: Best model checkpoint not found.\"); model = diplomacy_model\n\n    print(\"Evaluating on test dataset...\"); eval_results = model.evaluate(test_dataset, verbose=1, return_dict=True)\n    test_loss = eval_results['loss']; test_acc = eval_results['accuracy']; test_recall_lie = eval_results.get('recall_lie', np.nan); test_precision_lie = eval_results.get('precision_lie', np.nan)\n    print(f\"\\nTest Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc:.4f}\\nTest Recall (Lie): {test_recall_lie:.4f}\\nTest Precision (Lie): {test_precision_lie:.4f}\")\n\n    print(\"Generating predictions for detailed metrics...\")\n    y_pred_probs = model.predict(test_dataset); y_pred_bin = (y_pred_probs > 0.5).astype(int).flatten(); y_true = labels_test\n\n    if len(y_true) != len(y_pred_bin):\n         print(f\"CRITICAL WARNING: Length mismatch true labels ({len(y_true)}) vs predictions ({len(y_pred_bin)}). Recalculating labels.\")\n         y_true_list_from_ds = [];\n         try:\n             for _, label_batch in test_dataset.as_numpy_iterator(): y_true_list_from_ds.extend(label_batch)\n             y_true = np.array(y_true_list_from_ds)\n             if len(y_true) > len(y_pred_bin): y_true = y_true[:len(y_pred_bin)]\n             elif len(y_true) < len(y_pred_bin): y_true= None\n         except tf.errors.OutOfRangeError: print(\"Could not recalculate labels. Metrics skipped.\"); y_true = None\n\n    if y_true is not None and len(y_true) == len(y_pred_bin):\n        f1_lie = f1_score(y_true, y_pred_bin, pos_label=0, zero_division=0); f1_truth = f1_score(y_true, y_pred_bin, pos_label=1, zero_division=0); f1_macro = f1_score(y_true, y_pred_bin, average='macro', zero_division=0); f1_weighted = f1_score(y_true, y_pred_bin, average='weighted', zero_division=0)\n        print(f\"\\nF1 Score (Lie=0): {f1_lie:.4f}\\nF1 Score (Truth=1): {f1_truth:.4f}\\nMacro F1 Score: {f1_macro:.4f}\\nWeighted F1 Score: {f1_weighted:.4f}\")\n        print(\"\\nClassification Report:\"); print(classification_report(y_true, y_pred_bin, target_names=['Lie (0)', 'Truth (1)'], digits=4, zero_division=0))\n\n        # 11. Plot Confusion Matrix\n        conf_matrix = confusion_matrix(y_true, y_pred_bin); plt.figure(figsize=(6, 5))\n        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred Lie(0)', 'Pred Truth(1)'], yticklabels=['Actual Lie(0)', 'Actual Truth(1)'])\n        plt.title(f'Baseline Hybrid (FastText, Tuned) CM\\nAcc:{test_acc:.3f}|MacroF1:{f1_macro:.3f}|Lie F1:{f1_lie:.3f}', fontsize=9); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.tight_layout()\n        plot_cm_path = os.path.join(OUTPUT_DIR, \"cm_baseline_hybrid_tuned_fasttext.png\");\n        try: plt.savefig(plot_cm_path); print(f\"Saved CM plot: {plot_cm_path}\")\n        except Exception as e: print(f\"Error saving CM plot: {e}\")\n        # plt.show()\n    else: print(\"Could not calculate detailed metrics.\")\n\n    print(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T13:42:24.782616Z","iopub.execute_input":"2025-04-15T13:42:24.783862Z","iopub.status.idle":"2025-04-15T13:53:24.410155Z","shell.execute_reply.started":"2025-04-15T13:42:24.783691Z","shell.execute_reply":"2025-04-15T13:53:24.409115Z"}},"outputs":[{"name":"stderr","text":"2025-04-15 13:42:28.653016: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744724548.889542      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744724548.957199      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"--- Loading Train/Val/Test Data ---\n\n--- Preprocessing ALL Data ---\n Preprocessed 17289 labeled messages. (Skipped 6 dialogues)\nCreating score lookup from 17289 samples...\nScore lookup created: 1389 entries (1389 unique). Skipped N/A: 0.\nAggregated samples into turns for 12 games.\nBuilding turn graph lookup (using A+I)...\nGraph lookup built: 312 turns processed.\n\n--- Tokenizing Text Data ---\nActual Vocab size used: 9946\n\n--- Preparing Train/Val/Test Data Splits ---\n Preprocessed 13132 labeled messages. (Skipped 5 dialogues)\n Preprocessed 1416 labeled messages. (Skipped 1 dialogues)\n Preprocessed 2741 labeled messages.\nPadded Shapes: Tr=(13132, 60), Vl=(1416, 60), Ts=(2741, 60)\n\n--- Downsampling Training Data ---\nOriginal Train counts: Lie(0)=591, Truth(1)=12541\nDownsampled Train counts: Lie(0)=591, Truth(1)=591\nDownsampled Shapes: Text=(1182, 60), Delta=(1182, 2), Labels=(1182,)\n\n--- Loading FastText Embeddings (Downloading if needed) ---\nFastText file not found at /kaggle/working/crawl-300d-2M.vec.\nDownloading FastText embeddings from https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip...\nDownload complete.\nExtracting FastText embeddings to /kaggle/working/...\nExtraction complete.\nLoading FastText vectors from: /kaggle/working/crawl-300d-2M.vec\nFound 1999995 vectors in 153.88s.\nPrepared embedding matrix: Shape (9946, 300)\n  Converted 8314 words (1631 misses).\n\n--- Creating tf.data Datasets ---\n","output_type":"stream"},{"name":"stderr","text":"2025-04-15 13:46:58.118075: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Datasets created.\n\n--- Building and Compiling Baseline Hybrid Model (FastText, Tuned) ---\nInitializing TextFeatureEncoder Embedding with pre-trained weights.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"diplomacy_hybrid\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"diplomacy_hybrid\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mTextFeatureEncoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                           │       \u001b[38;5;34m2,983,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (\u001b[38;5;33mMultiHeadAttention\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (\u001b[38;5;33mAdd\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (\u001b[38;5;33mDropout\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (\u001b[38;5;33mDense\u001b[0m)    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (\u001b[38;5;33mDropout\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (\u001b[38;5;33mDense\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (\u001b[38;5;33mGraphEncoder\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ cast_mask_to_float_ge (\u001b[38;5;33mLambda\u001b[0m)  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ expand_mask_dim_ge (\u001b[38;5;33mReshape\u001b[0m)    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ mask_nodes_ge (\u001b[38;5;33mMultiply\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn1 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn2 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (\u001b[38;5;33mGCNLayer\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn3 (\u001b[38;5;33mDropout\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_pooled (\u001b[38;5;33mDropout\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (\u001b[38;5;33mDense\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (\u001b[38;5;33mConcatenate\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (\u001b[38;5;33mDense\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason1 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason2 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (\u001b[38;5;33mDense\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text_feature_encoder                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextFeatureEncoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,983,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ add_resid_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ norm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_pooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dense_delta_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ concat_text_features            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                        │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ text_feature_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ graph_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphEncoder</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ cast_mask_to_float_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ expand_mask_dim_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ mask_nodes_ge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ CustomGCN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_gcn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ GraphPooling                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ dropout_pooled (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│    └ graph_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ combine_embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reason_attention                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_reason2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,983,800\u001b[0m (11.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,983,800</span> (11.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,983,800\u001b[0m (11.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,983,800</span> (11.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n--- Starting Training ---\nTraining Steps per Epoch: 37\nEpoch 1/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.5312 - loss: 0.6887 - precision_lie: 0.5204 - recall_lie: 0.5237\nEpoch 1: val_loss improved from inf to 0.54650, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 665ms/step - accuracy: 0.5320 - loss: 0.6885 - precision_lie: 0.5213 - recall_lie: 0.5254 - val_accuracy: 0.8298 - val_loss: 0.5465 - val_precision_lie: 0.9714 - val_recall_lie: 0.8478\nEpoch 2/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.5925 - loss: 0.6655 - precision_lie: 0.5857 - recall_lie: 0.6159\nEpoch 2: val_loss improved from 0.54650 to 0.53310, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.5931 - loss: 0.6652 - precision_lie: 0.5863 - recall_lie: 0.6161 - val_accuracy: 0.7924 - val_loss: 0.5331 - val_precision_lie: 0.9734 - val_recall_lie: 0.8059\nEpoch 3/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 0.6248 - loss: 0.6247 - precision_lie: 0.6221 - recall_lie: 0.6261\nEpoch 3: val_loss did not improve from 0.53310\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 607ms/step - accuracy: 0.6243 - loss: 0.6251 - precision_lie: 0.6218 - recall_lie: 0.6250 - val_accuracy: 0.7917 - val_loss: 0.5630 - val_precision_lie: 0.9717 - val_recall_lie: 0.8066\nEpoch 4/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.6179 - loss: 0.6534 - precision_lie: 0.5943 - recall_lie: 0.6463\nEpoch 4: val_loss did not improve from 0.53310\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 605ms/step - accuracy: 0.6188 - loss: 0.6527 - precision_lie: 0.5955 - recall_lie: 0.6473 - val_accuracy: 0.7465 - val_loss: 0.5332 - val_precision_lie: 0.9753 - val_recall_lie: 0.7551\nEpoch 5/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.6598 - loss: 0.6202 - precision_lie: 0.6498 - recall_lie: 0.6950\nEpoch 5: val_loss did not improve from 0.53310\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.6600 - loss: 0.6198 - precision_lie: 0.6501 - recall_lie: 0.6947 - val_accuracy: 0.7232 - val_loss: 0.5956 - val_precision_lie: 0.9672 - val_recall_lie: 0.7368\nEpoch 6/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.6812 - loss: 0.6082 - precision_lie: 0.6642 - recall_lie: 0.6985\nEpoch 6: val_loss improved from 0.53310 to 0.43950, saving model to /kaggle/working/baseline_hybrid_tuned_fasttext.keras\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 610ms/step - accuracy: 0.6808 - loss: 0.6085 - precision_lie: 0.6643 - recall_lie: 0.6976 - val_accuracy: 0.8884 - val_loss: 0.4395 - val_precision_lie: 0.9673 - val_recall_lie: 0.9147\nEpoch 7/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.6548 - loss: 0.5998 - precision_lie: 0.6203 - recall_lie: 0.7696\nEpoch 7: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 0.6553 - loss: 0.5996 - precision_lie: 0.6211 - recall_lie: 0.7689 - val_accuracy: 0.8178 - val_loss: 0.4965 - val_precision_lie: 0.9669 - val_recall_lie: 0.8390\nEpoch 8/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.7154 - loss: 0.5542 - precision_lie: 0.6836 - recall_lie: 0.8025\nEpoch 8: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 578ms/step - accuracy: 0.7155 - loss: 0.5541 - precision_lie: 0.6840 - recall_lie: 0.8016 - val_accuracy: 0.6469 - val_loss: 0.7191 - val_precision_lie: 0.9705 - val_recall_lie: 0.6522\nEpoch 9/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.7337 - loss: 0.5152 - precision_lie: 0.7155 - recall_lie: 0.7590\nEpoch 9: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 0.7339 - loss: 0.5152 - precision_lie: 0.7158 - recall_lie: 0.7592 - val_accuracy: 0.5177 - val_loss: 0.8102 - val_precision_lie: 0.9721 - val_recall_lie: 0.5125\nEpoch 10/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.7783 - loss: 0.4606 - precision_lie: 0.7834 - recall_lie: 0.7535\nEpoch 10: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 582ms/step - accuracy: 0.7785 - loss: 0.4606 - precision_lie: 0.7833 - recall_lie: 0.7547 - val_accuracy: 0.7747 - val_loss: 0.5274 - val_precision_lie: 0.9651 - val_recall_lie: 0.7941\nEpoch 11/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.8147 - loss: 0.3977 - precision_lie: 0.7972 - recall_lie: 0.8380\nEpoch 11: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 569ms/step - accuracy: 0.8144 - loss: 0.3981 - precision_lie: 0.7970 - recall_lie: 0.8376 - val_accuracy: 0.5410 - val_loss: 1.0257 - val_precision_lie: 0.9746 - val_recall_lie: 0.5360\nEpoch 12/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.8278 - loss: 0.3816 - precision_lie: 0.8271 - recall_lie: 0.8267\nEpoch 12: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 585ms/step - accuracy: 0.8280 - loss: 0.3813 - precision_lie: 0.8271 - recall_lie: 0.8273 - val_accuracy: 0.4880 - val_loss: 1.3109 - val_precision_lie: 0.9676 - val_recall_lie: 0.4831\nEpoch 13/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.8638 - loss: 0.3282 - precision_lie: 0.8661 - recall_lie: 0.8694\nEpoch 13: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.8638 - loss: 0.3282 - precision_lie: 0.8657 - recall_lie: 0.8696 - val_accuracy: 0.4689 - val_loss: 1.5602 - val_precision_lie: 0.9691 - val_recall_lie: 0.4618\nEpoch 14/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.8650 - loss: 0.2792 - precision_lie: 0.8747 - recall_lie: 0.8572\nEpoch 14: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 574ms/step - accuracy: 0.8645 - loss: 0.2802 - precision_lie: 0.8738 - recall_lie: 0.8572 - val_accuracy: 0.3425 - val_loss: 1.7243 - val_precision_lie: 0.9673 - val_recall_lie: 0.3265\nEpoch 15/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.8181 - loss: 0.3629 - precision_lie: 0.8289 - recall_lie: 0.8046\nEpoch 15: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 586ms/step - accuracy: 0.8186 - loss: 0.3625 - precision_lie: 0.8288 - recall_lie: 0.8057 - val_accuracy: 0.6815 - val_loss: 0.8581 - val_precision_lie: 0.9720 - val_recall_lie: 0.6882\nEpoch 16/50\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.8503 - loss: 0.3408 - precision_lie: 0.8465 - recall_lie: 0.8555\nEpoch 16: val_loss did not improve from 0.43950\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 581ms/step - accuracy: 0.8506 - loss: 0.3402 - precision_lie: 0.8468 - recall_lie: 0.8559 - val_accuracy: 0.5621 - val_loss: 1.2393 - val_precision_lie: 0.9684 - val_recall_lie: 0.5625\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 6.\n\n--- Evaluating Model on Test Set ---\nLoading best model from: /kaggle/working/baseline_hybrid_tuned_fasttext.keras\nError loading model: <class '__main__.DiplomacyHybridModel'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': None, 'class_name': 'DiplomacyHybridModel', 'config': {'name': 'diplomacy_hybrid', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 140048335029456}, 'reason_dropout_rate': 0.4, 'attention_heads': 4}, 'registered_name': 'DiplomacyHybridModel', 'build_config': {'input_shape': [[60], [2], [7, 1], [7, 7], [7]]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'AdamW', 'config': {'name': 'adamw', 'learning_rate': 7.999999797903001e-05, 'weight_decay': 0.0001, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy', {'module': 'keras.metrics', 'class_name': 'Recall', 'config': {'name': 'recall_lie', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': 0}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Precision', 'config': {'name': 'precision_lie', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': 0}, 'registered_name': None}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: TextFeatureEncoder.from_config() got an unexpected keyword argument 'custom_objects'. Evaluating with final weights.\nEvaluating on test dataset...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.8829 - loss: 0.4363 - precision_lie: 0.9510 - recall_lie: 0.9222\n\nTest Loss: 0.4598\nTest Accuracy: 0.8581\nTest Recall (Lie): 0.9100\nTest Precision (Lie): 0.9328\nGenerating predictions for detailed metrics...\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step\n\nF1 Score (Lie=0): 0.2810\nF1 Score (Truth=1): 0.9213\nMacro F1 Score: 0.6011\nWeighted F1 Score: 0.8652\n\nClassification Report:\n              precision    recall  f1-score   support\n\n     Lie (0)     0.2525    0.3167    0.2810       240\n   Truth (1)     0.9328    0.9100    0.9213      2501\n\n    accuracy                         0.8581      2741\n   macro avg     0.5926    0.6134    0.6011      2741\nweighted avg     0.8732    0.8581    0.8652      2741\n\nSaved CM plot: /kaggle/working/cm_baseline_hybrid_tuned_fasttext.png\n\n--- Script Finished ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":1}]}